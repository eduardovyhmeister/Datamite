name, alternative_names, bsc_subfamilies, short_definition, explanation
Access Cost, "[\"Bandwitdh Cost\"]", "[\"Data Valuation Techniques\"]", "The cost (not necessarily the price) incurred for accessing a dataset.", "The cost (not necessarily price) incurred for accessing a dataset based on historical access logs and the cloud provider's pricing (if existing). This metric directly refers to the cost incurred when accessing data, which is influenced by bandwidth, especially in geodistributed data systems where data needs to be transferred over long distances."
Accessibility, "[\"Search\", \"Functionality\", \"Navigation\", \"Link\"]", "[\"Data Valuation Techniques\", \"Data Governance and Compliance\", \"Technology and Infrastructure\"]", "Accessibility in data and information systems refers to how easily users can access, understand, and utilize data factoring in availability, usability, interoperability, inclusivity, security, licensing, and standardized formatting to maximize its value and usability.", "Accessibility, in the context of data and information systems, refers to the ease with which users can access and utilize data. It encompasses several key aspects:\nAvailability: Data should be readily available to authorized users when needed, without unnecessary delays or barriers.\nUsability: The data should be presented in a format that is easy to understand and navigate, allowing users to efficiently find and use the information they need.\nInteroperability: Data should be compatible with various systems and applications, enabling seamless integration and exchange of information across different platforms.\nInclusivity: Accessibility also considers the needs of diverse user groups, including those with disabilities. This means ensuring that data and information systems are designed to be usable by individuals with varying abilities, such as providing alternative formats or assistive technologies.\nSecurity and Permissions: While ensuring accessibility, it is also important to manage access controls and permissions to protect sensitive data from unauthorized access.\nOpen to use / licensing: There is no limit on users to use the data.\nFormat: Follow prestrucutred definitions for the data content strucutre, for example, does the dataset match Berners-Lee's 'linked data principles'?\nOverall, accessibility is crucial for maximizing the value of data, as it ensures that users can effectively leverage the information for decision-making, analysis, and other purposes. Measures how accessible the platform is for users in terms of ease of navigation, search, and data retrieval."
Accuracy, "[]", "[\"Data Quality\"]", "Accuracy is a multifaceted measure of how well data aligns with true or expected values, encompassing elements like precision, relevance, timeliness, completeness, and context to ensure reliability and validity in achieving research objectives.", "Accuracy in the context of scientific analysis is a comprehensive measure of how closely data or results align with the true, intended, or expected values. It encompasses multiple facets that ensure the reliability, applicability, and validity of the information within the specific scientific domain. The accuracy of data or results is not only about correctness but also about their overall suitability for achieving the desired objectives in a given context.\nThe complexity of the relationship between accuracy and the value gained depends on the type of information and the organization. Moreover, unless specified, the basic calculation of value obtained by meeting the required accuracy. As defined by [12] Accuracy is depends on Range, Consistency, Typicality and Moderation Metrics. Nevertheless, different key elements can also be used to explain accuracy:\nPrecision: Refers to the granularity or level of detail in the data. In science, precision ensures that measurements are not only correct but also detailed enough to provide meaningful insights. For example, reporting a temperature as 37.456°C instead of rounding to 37°C can be crucial in laboratory experiments.\nTimeliness: Information must reflect the most current state. In scientific research, outdated data can lead to incorrect conclusions, making the timeliness of updates or recalibrations essential.\nRelevance: Accuracy is context-dependent. Data must be both correct and directly applicable to the research question or hypothesis. For instance, accurate but irrelevant data adds no value to the scientific inquiry.\nCompleteness: Scientific accuracy requires that no critical data points are missing. Incomplete datasets can lead to skewed or biased results, undermining the validity of findings.\nTraceability: The provenance of data ensures it can be verified and validated. For science, traceability means being able to track data back to its source, such as instrumentation or observation records, to confirm its authenticity.\nTolerance and Range: Recognizes that minor inaccuracies or deviations may be acceptable within specified thresholds. Scientific accuracy involves defining these thresholds to minimize the impact on overall validity. Furthermore, in terms of range it specifies limits for acceptance too.\nContext Dependence: Accuracy must meet the specific standards and expectations of the scientific discipline. For example, a minor deviation in physics experiments might be acceptable, whereas in clinical trials, even small inaccuracies can have serious consequences.\nConsistency: Data should be reliable and uniform across various trials or applications. Inconsistencies in repeated experiments can signal issues with data accuracy.\nTypicality: Measures whether the data reflects typical or expected conditions. Atypical data may require additional validation to ensure its accuracy.\nModeration: Ensures data is not skewed or biased toward extremes. Balanced data contributes to overall scientific accuracy by avoiding distortions."
Adaptability, "[\"Versatility\", \"Flexibility\"]", "[\"Operational Efficiency\"]", "Relates to how well a system can adjust to changes in its environment, such as varying network conditions, changing user needs, or different operating contexts.", "Relates to how well a system can adjust to changes in its environment, such as varying network conditions, changing user needs, or different operating contexts. Adaptable systems make scalability more efficient because they can dynamically adjust their resources and behavior to accommodate growth. "
Age, "[\"Data Creation\", \"Time Index\", \"Age of Information\"]", "[\"Data Quality\"]", "Refers to how recent or old the data is.", "Refers to how recent or old the data is. The age of data can impact its relevance and accuracy, especially in fast-moving fields like technology or finance."
Availability, "[\"Retrievability\"]", "[\"Operational Efficiency\"]", "Data availability refers to the reliable, timely, and uninterrupted access to data by authorized users, supported by system robustness, fault tolerance, backups, and redundancy to ensure operational continuity and effective decision-making.", "Data availability refers to the degree to which data is accessible and retrievable when needed, by authorized users or systems. It ensures that the data can be accessed in a timely manner without interruption, and is crucial for maintaining smooth operations, decision-making, and service continuity. As a KPI it could have the following Key Aspects:\nAccessibility: Ensuring that the data is available to authorized users when they need it, whether for operational or analytical purposes. (i.e. binary per dataset) \nReliability (Measure throughout System Robustness): The data should be consistently available without frequent downtime or failures.\nFault tolerance (Measured through System Robustness): Systems storing the data should be resilient to hardware or software failures, ensuring minimal disruption in data access. \nBackup: Implementing regular backups and quick recovery solutions ensures that data is still available after incidents like data corruption or system failures.\nRedundancy: Data availability can be enhanced through redundant systems (e.g., having multiple copies of the data across servers), so if one system fails, another is still operational."
Backup, "[\"System Backup\", \"Recovery Capabilities\", \"Data Redundancy\", \"Reduction\"]", "[\"Operational Efficiency\"]", "A system's ability to securely preserve data and ensure its availability for recovery during disruptions, emphasizing robust mechanisms and minimal data loss.", "A system's ability to securely preserve data and ensure its availability for recovery during disruptions, emphasizing robust mechanisms and minimal data loss. The opposit perspective of backup is Data Redundancy Reduction, that can be a metric when the objective is a scalable services (big IoT services) without considreable repetition, as mentioned in [105]."
Budget, "[\"Costs Planned\", \"IT Plan\", \"Plan\"]", "[\"Data Monetization\"]", "A budget is a financial plan that outlines expected income and expenditures over a specific period.", "A budget is a financial plan that outlines expected income and expenditures over a specific period. It represents an estimate of how much money an individual, business, government, or organization expects to earn (revenue) and how much it plans to spend (expenses) to achieve certain financial or operational goals."
Cache Size, "[]", "[\"Technology and Infrastructure\"]", "Cache size refers to the amount of data (e.g gigabytes) that a cache can store at any given time.", "Cache size refers to the amount of data (measured in units such as kilobytes, megabytes, gigabytes, etc.) that a cache can store at any given time. The cache is a high-speed data storage layer that stores a subset of data, typically temporary, to serve future requests more quickly than retrieving the data from its primary storage or origin location."
CAPEX, "[\"Capital Cost\", \"Hardware Costs\", \"Software/Application Costs\", \"Service Cost\", \"Infrastructure Unit Costs\"]", "[\"Data Monetization\"]", "CAPEX refers to one-time investments in long-term physical and technological assets—like hardware for data capture, storage, and processing—essential for building or upgrading data systems, with costs sometimes offset by asset depreciation or pre-installed software.", "CAPEX refers to the one-time, upfront investments made to acquire, upgrade, or maintain physical assets or infrastructure, independent on the number of quotes needed to cover this expense. These expenses are typically for assets that have a useful life beyond the current accounting period, such as:\n(1) Purchasing new machinery or equipment; (2) Constructing buildings or facilities; (3) Upgrading technology infrastructure (e.g., data centers, servers); (4) Acquiring servers or other long-term assets; (5) Investing in property or land.\nTo be more specific, hardware cost (past of CAPEX) for a data and information system encompasses the following components:\n(1) Data Capturing Hardware: Computers and devices used to collect and input data; (2) Acquisition Systems: Sensors, data acquisition (DAQ) systems, and similar tools for measuring and capturing values; (3) Information Collection Mediums: Devices like PDAs and tablets used for collecting data. (4) Data Storage Hardware: Systems for storing large volumes of data. (5) Data Processing and Analysis Hardware: Computers and servers for processing and analyzing data.\nIf existing hardware is repurposed, the cost should be based on its depreciation during use. If fully depreciated, the cost is effectively zero.\nFurthermore, A significant aspect of Data is the processing, storing, and viewing of it. This requires specialized software to accomplish unlike small data sets. This software can cost and needs to be incorporated into the total costs of the Data system. Although the cost of this software can be significant, other software such as Microsoft Office are often used for data analysis. These types of software are typically pre-installed on the computers bought by organizations and used by employees. Therefore, they normally run at zero cost for the node and can excluded from its costs."
Carbon Usage Effectiveness, "[\"CUE\"]", "[\"Innovation and Growth\"]", "A carbon metric used to measure the environmental impact by assessing the amount of CO2 emissions per unit of IT energy consumed. ", "A carbon metric used to measure the environmental impact by assessing the amount of CO2 emissions per unit of IT energy consumed."
Carbon Emission Factor, "[\"CEF\"]", "[\"Innovation and Growth\"]", "The amount of carbon dioxide (CO2) emissions produced per unit of energy consumed, typically expressed in kilograms of CO2 per kilowatt-hour (kgCO2/kWh).", "Coefficient used to calculate the amount of carbon dioxide (CO2) emissions produced per unit of energy consumed, typically expressed in kilograms of CO2 per kilowatt-hour (kgCO2/kWh). It varies depending on the energy source (e.g., coal, natural gas, renewable energy) and the region's energy mix."
Churn, "[]", "[\"Customer Needs and Satisfaction\", \"Market Penetration\"]", "Churn refers to customer loss, and predicting it involves analyzing data such as demographics, usage patterns, transactions, interactions, sentiment, and external factors to help businesses retain customers proactively.", "The term churn refers to the loss of customers, and predicting churn helps businesses take proactive measures to retain customers before they leave. Data Used for Churn Prediction: \nCustomer Demographics: Age, gender, location, and other personal information that can give insights into churn behaviour.\nUsage Patterns: How often and in what way customers use the service (e.g., call frequency, data usage, purchase frequency).\nTransaction History: Purchase or payment records, subscription renewals, or cancellations.\nInteraction Data: Customer interactions with the company's customer service, support requests, or social media engagement.\nSentiment Analysis: Textual data from customer feedback, complaints, or reviews that can reveal dissatisfaction.\nExternal Data: Market trends, economic factors, or competitor actions that may influence customer churn."
Clarity, "[\"Understandability\", \"Easy to Understand\", \"Lack of Confusion\", \"Unambiguity\", \"Concise\", \"Readability\", \"Interpretability\"]", "[\"Customer Needs and Satisfaction\", \"Market Penetration\"]", "Clarity in data refers to how easily it can be understood and interpreted, emphasizing simplicity, structure, consistency, readability, contextual explanation, appropriate visualization, and completeness to ensure users can draw accurate insights without confusion.", "Clarity in the context of data refers to how easily the data can be understood, interpreted, and used by its intended audience. It involves presenting data in a way that is straightforward, unambiguous, and free from unnecessary complexity. Clear data allows users to quickly grasp its meaning, draw insights, and make decisions without confusion or misinterpretation. The key aspects of data clarity from a KPI perspective are:\nSimplicity and Structure: Data should be presented in a well-organized manner, often through tables, graphs, or summaries that make complex data easier to digest. Example: Using clear, concise headers in a dataset and avoiding overly complex structures.\nConsistency: Consistent terminology, formats, and units of measurement improve clarity. Data should follow the same structure and presentation style across the dataset.\nReadability: Data should be easily readable, with clear labels, appropriate formatting, and a clean layout. Good readability ensures that the user can navigate the data without confusion.\nContext, Metadata, and/or Explanation: Providing context or explanations (e.g., metadata, labels, or definitions) that clarify what the data represents.\nRedundancy/Containment Fraction: Data should be free from unnecessary repetition or irrelevant (Within the same dataset only, since redundancy is important for availability) information that can clutter the understanding. Example: Avoiding the use of the same information in multiple columns or rows when that doesn't add value to an analysis.\nVisualization: Using the right type of visualization (charts, graphs, maps, etc.) can enhance clarity by making patterns, trends, or insights easier to recognize.\nCompleteness: checks if the dataset has all the required fields and values without missing information (measured as a percentage).\nNot all these factors are included in the main taxonomy figure, for simplicity they have been reduced there. Nevertheless, these factors could be considered as a base since several of the main components here can be bound to readability, conciseness, and understandability."
CO2 Savings, "[]", "[\"Innovation and Growth\", \"Operational Efficiency\"]", "CO2 Savings measures the reduction in data center carbon emissions from a baseline, reflecting the impact of energy optimization, renewable integration, and heat recovery strategies like those implemented in the GENiC system.", "The metric CO2 Savings refers to the change in data center CO2 emissions from a given baseline. This metric evaluates the reduction in CO2 emissions achieved by implementing the GENiC system and its integrated management strategies for optimizing energy usage, renewable energy integration, and heat recovery in data centers."
Completeness, "[\"Appropriate Amount of Data\"]", "[\"Data Quality\"]", "Completeness in data refers to the extent to which all necessary and expected information is present in a dataset, ensuring mandatory fields are filled, missing values are minimal, and the data is sufficiently detailed for accurate analysis.", "Completeness in data refers to the extent to which all required data is available and present within a dataset. It measures how much of the expected information is provided, indicating whether or not critical data fields are missing or left blank.\nKey aspects of data completeness include:\nPresence of mandatory fields: All required fields have values.\nProportion of missing data: A low percentage of missing or null values indicates better completeness.\nConsistency with expectations: The dataset should align with the expected structure and content, covering all data points.\nGranularity: The data should provide enough detail to meet the desired level of analysis.\nFor example, in a customer database, completeness would ensure that fields like customer names, addresses, and contact details are filled for every record. A lack of data in important fields would indicate incomplete data."
Regulatory Compliance, "[\"Compliance Cost\"]", "[\"Data Governance and Compliance\"]", "Compliance measures the extent to which data adheres to legal, regulatory, and organizational standards, assessing both the alignment with required rules and the potential financial risks of non-compliance.", "Regulatory Compliance measures whether the data complies with relevant legal and regulatory standards. Estimated financial cost to business of not keeping data for compliance/regulation purposes. It can be defined as a quantitative or qualitative measure that evaluates the extent to which data adheres to the predefined rules, standards, or requirements. Compliance metrics focus on ensuring data consistency, reliability, and alignment with organizational or regulatory frameworks."
Conciseness, "[\"Concise Representation\", \"Simplicity\"]", "[\"Data Quality\"]", "Conciseness in data refers to presenting essential information clearly and efficiently, minimizing redundancy and irrelevant details while maintaining clarity, relevance, and semantic consistency for effective communication and understanding.", "Conciseness refers to the principle of presenting data or information in a way that is both brief and clear, without unnecessary detail or redundancy. The goal is to convey the essential meaning or facts in the most straightforward and efficient manner possible, while still being complete and accurate. Key Characteristics of Concise Representation could include (To chose from the tyep of system considerations):\nBrevity/Compression: The information is presented using the fewest words, symbols, or data points necessary to communicate the intended meaning. It also Reflects how much data can be compacted without losing critical information. \nClarity: The content is clear and easy to follow, even when reduced to its essential elements. \nEfficiency/Signal-to-noise Ratio: It avoids redundancy, long-winded explanations, or superfluous data that could confuse or overwhelm the user. Also, can be considered as the proportion of useful, relevant information (signal) to irrelevant or extraneous data (noise). \nRedundancy: Measures the repetition of identical or similar data within a system or dataset.\nRelevance: Only the most relevant information is included, eliminating any extraneous data that doesn't add value to the understanding of the content.\nSemantic Consistency: Measures alignment and consistency in the terminology and format used across the dataset.\nDuplicate Elimination: a measure for the process of identifying and removing identical or near-identical records."
Confidence, "[]", "[\"Operational Efficiency\", \"Data Quality\"]", "TODO", "The confidence metric measures how strongly a dependency (MD or MFD TODO: unclear what these are.) holds in the dataset."
Consistency, "[\"Heterogeneity\", \"Veracity\"]", "[\"Data Quality\"]", "Consistency in data refers to the uniformity, reliability, and rule-conformance of data across systems, ensuring accuracy, coherence, and integrity by validating against predefined rules and maintaining synchronization across datasets.", "Consistency refers to how well data values conform to predefined rules, such as association rules in the context of relational databases. The metric for consistency, as defined by Alpar and Winkelsträter [118], evaluates the consistency of a tuple t based on whether it fulfills or violates certain rules r from a set R of association rules. Consistency, in the context of data management and information systems, refers to the uniformity and reliability of data across different datasets, systems, and applications. It ensures that data remains accurate, coherent, and free from contradictions, which is essential for maintaining data integrity and trustworthiness. Key aspects of consistency (for a KPI consideration) include: Data Integrity, Uniformity, Synchronization, Rules validation, Error Prevention, and Governance."
Containment Fraction, "[]", "[\"Operational Efficiency\", \"Data Quality\"]", "Measures the extent to which one dataset is contained within another.", "Measures the extent to which one dataset is contained within another. This metric helps identify redundancy and optimize storage usage. A limit in containment fraction has to exist since availability depends on duplication, for security, of the same information."
Cooling Effectiveness Rate, "[\"CER\", \"Energy Effectiveness of Cooling\"]", "[\"Operational Efficiency\"]", "Focuses on the effectiveness of cooling systems in the data center.", "Focuses on the effectiveness of cooling systems in the data center. There are direct linkage to other metrics related to cooling effectivenes, such as ”Energy Effectiveness of Cooling Mode in a Season”. Assesses how effectively the cooling system operates in different seasons, which can influence operational costs and carbon emissions."
Cost of Degradation, "[\"CoD\"]", "[\"Data Quality\"]", "Cost of Degradation measures the reduction in data quality caused by transformations, particularly in privacy-preserving contexts. It helps quantify how much value the data has lost through necessary adjustments for privacy.", "Cost of Degradation measures the reduction in data quality caused by transformations, particularly in privacy-preserving contexts. It helps quantify how much value the data has lost through necessary adjustments for privacy."
Data Acquisition Cost, "[\"DAC\"]", "[\"Data Monetization\"]", "Data Acquisition Cost (DAC) represents the proportion of data or local models that a Data Acquirer must obtain from Data Providers during each federated learning training epoch to build an accurate global model, serving as a non-monetary measure of acquisition effort.", "Data Acquisition Cost (DAC) refers to the cost, typically measured as a percentage, associated with acquiring local models from the Data Providers (DPs) during each training epoch in a federated learning setup. The DAC represents the fraction of data or local models the Data Acquirer (DA) needs to purchase or gather from the DPs to train an accurate and effective global model. In the traditional sense, DAC is not directly a monetary cost; rather, it represents the fraction of available data or local models that must be procured. All other costs are encapsulated within the metric Cost (e.g. Purchase Cost, OPEX, etc.)."
Data Centre Adaptation, "[\"Data Centre Energy Profile Change\"]", "[\"Operational Efficiency\"]", "The Data Centre Adaptation (DCA) metric measures the change in a data center's energy profile from a predefined baseline, reflecting its adaptability, energy efficiency, and integration of renewable energy within the GENiC framework.", "The Data Centre Energy Profile Change is referred to as DCA (Data Centre Adaptation) in the context of energy metrics outlined in the GENiC framework from the manuscript. It captures the change in the data center's energy profile from a predefined baseline. This metric is part of a broader set of evaluation measures used to assess energy efficiency, sustainability, and the ability to adapt to renewable energy integration [44]."
Data Ingestion Capabilities, "[\"Data Collection and Management Capabilities\", \"Data Analysis\", \"Data Mining\", \"Data Sources\"]", "[\"Technology and Infrastructure\"]", "Data Ingestion Capabilities refer to a system's ability to efficiently collect, process, and store large volumes of data from diverse sources in real time, ensuring high throughput, low latency, scalability, and data integrity, especially in high-velocity environments like IoT.", "Data Ingestion Capabilities refer to the ability of a system to effectively and efficiently handle the process of acquiring, collecting, and storing data from various sources. This capability is critical for managing large-scale, high-velocity data flows, especially in contexts like IoT applications, where data is generated continuously by sensors and devices. Effective data ingestion ensures the system's ability to (key components): Handle High Throughput (Throughput), Accommodate Delays (Latency, and handling delayed data), Ensure Scalability (e.g. Scalability is evaluated by testing throughput and latency as the number of devices, sensors, or data points increases), Maintain Data Integrity. In practice, this involves technologies like time-series databases, message queues (e.g., Kafka), and specialized data formats like TsFile for compression and organization."
Data Price, "[\"Data Value\", \"Price Function\", \"Payoff Reimbursement\", \"Financial Value\", \"Price of Information\"]", "[\"Data Monetization\"]", "Data price refers to the monetary value assigned to data, determined through models or market mechanisms, incorporating factors like cost, contribution rewards, compensation, and volume-based pricing using approaches such as entropy valuation, utility models, or dynamic pricing.", "Data price is the financial value assigned to data, determined through models or market mechanisms. It encompasses concepts like monetary cost, price functions, payoff (reward for contributions), reimbursement (compensation for costs), and volume-based metrics (e.g., price per MB). Methodologies include entropy-based valuation, utility models, and dynamic pricing, tailored to specific contexts such as privacy, real-time trading, or structured markets."
Oversight, "[\"Audit\"]", "[\"Data Governance and Compliance\"]", "Governance Audit Capability assesses an organization's ability to monitor, validate, and ensure adherence to governance standards through mechanisms like periodic audits and compliance checks.", "Assesses the organization's capability to monitor and validate compliance with governance standards, processes, and policies. It includes mechanisms for periodic audits to ensure data integrity and proper governance implementation."
Data Principles and Practices, "[\"Data-Standard Driven\", \"Standardization\"]", "[\"Data Governance and Compliance\"]", "Data Quality Compliance measures the extent to which an organization adheres to defined data standards and principles, reflecting its commitment to ensuring data consistency, reliability, and alignment with organizational goals through quantifiable metrics.", "This metric measures the degree to which an organization adheres to defined data standards and principles to maintain data quality and governance. It emphasizes commitment to data quality policies, ensuring data is consistent, reliable, and aligned with organizational objectives [97], [57], [54].\nKey components:\nCommitment to Data Quality: Demonstrates adherence to predefined data standards and a commitment to maintaining high-quality data across systems and processes [57], [54].\nQuantifiable Standards: Measures compliance through clear metrics, such as achieving specific scores or thresholds in data quality assessments [57], [54]."
Data Similarity, "[\"Euclidian Distance\", \"Projection Similarity\", \"Similarity Score\", \"Cosine Similarity\", \"Average Distance\", \"Kolmogorov-Smirnov (KS)\", \"Mann-Whitney (MW)\", \"Mood s Median (MD)\", \"Levene (LE)\"]", "[\"Data Quality\"]", "Data Similarity refers to the numerical measurement of how closely related two data points or datasets are, typically using distance or similarity metrics like Euclidean Distance or Cosine Similarity, and is distinct from syntactic similarity due to its focus on numerical attributes.", "These metrics are a measure to compute the distance between two points within a given space, commonly applied to numerical attributes. Such metrics are distinguished from syntactic similarity due to their numerical basis. Projection Similarity, for instance, calculates the similarity of datasets based on feature dimensions from other datasets."
Data Type, "[]", "[\"Data Valuation Techniques\"]", "Data can be classified into categories (A–D) based on its intended use, ranging from time-sensitive operational data to long-term legal, decision-making, or research-related data, each with distinct characteristics in terms of frequency, lifespan, value realization, and sensitivity.", "Depending on the possible use of the data, it can be classified. In [117], is classified or scored on the decision-based valuation method. (A, B, C, and D) A is operational data (i.e. It has a predetermined frequency; It has a short usable life span proportional to its frequency; It is very time sensitive and its value depreciates rapidly after its timeframe; and Its value is quickly realized through its use.) B is a One Time Decision Data (i.e. It does not have a predetermined frequency; It has a usable life span of the length of the decision; It is often not very time sensitive; There is a high emphasis on accuracy; It has a high value but often a high cost as well; and Its value takes a long period of time to be realized.) Type C is Legal and Safety Data (i.e. It has almost no value to the organization; The true value of the data can only be estimated on the probability of its need; It often has to be stored for a minimum of five years if not longer; The organization is legally required to collect and store it; There can often be a legally required frequency; and It can have an indefinite life span.) and D is Research and Innovation data (i.e. It has a very low chance of providing future incomes; It is difficult to predict whether it will provide value; It has a large value range; and It has a long life span). TODO: This explanation is horrendous, need to find a better way to make this clear."
Data Value, "[\"DV\", \"Data Criticallity\", \"Value of Information\", \"Fixed Record Value\", \"IP Value\", \"Intrinsic Record Value\"]", "[\"Data Valuation Techniques\"]", "Data value refers to the level of usefulness or relevance data holds for a specific consumer or context, varying with application needs, and is often assessed through factors like cost, lifecycle, and criticality to business operations and decision-making.", "Level of usefulness or relevance a data object has for a particular data consumer, which can vary depending on the consumer's application context and specific needs. This means that Data Value is not static; it changes based on how well the data fits the purpose it's being used for, even if the Data Quality (DQ) of the data remains constant. For distribucion services it can measures the value of a decision node in the Decision-Based Valuation (DBV) framework, taking into account factors like cost and lifecycle. Also, can refer to Data Criticality: refers to the importance of data for both consumers and the company. It evaluates how essential certain data is in the context of business operations and decision-making. The measure of data criticality assesses the impact that data has on the organization and its customers, particularly regarding its role in supporting business processes, revenue generation, and service delivery."
Data Value Ratio, "[\"VR\"]", "[\"Data Valuation Techniques\"]", "The Data Value Ratio (VR) represents the proportion of a decision node's value attributed to a specific data source.", "The Data Value Ratio (VR) represents the proportion of a decision node's value attributed to a specific data source."
Demand, "[\"Score\", \"Number of Data Consumers\"]", "[\"Data Monetization\"]", "Data demand refers to the desirability or market need for specific data types, typically measured through buyer willingness-to-pay scores or strategic value within a broader data value chain, often informing pricing and data management strategies.", "The demand or score for data is defined differently depending on the system under consideration and thus, the strategy to be implemented. For example, in the [TODO: Broken reference], demand for data is conceptualized as buyers' willingness to pay for specific types of information. This demand is measured using a scoring mechanism where buyers rate the desirability of different categories of data. The resulting score reflects the demand for that data type in the market. Combined with the data's utility (a measure of how much the data quality degrades after privacy-preserving obfuscation), these scores are used to establish a pricing model for information. In [TODO: Broken reference], demand or value of data is analyzed as part of a broader data value chain management. Here, demand is less about individual buyers and more about the data's role in enabling strategic decisions, cost efficiency, and economic outcomes."
Detail, "[]", "[\"Data Quality\"]", "Data Detail refers to the level of specificity and descriptive richness in a dataset, typically measured through granularity, number of descriptive attributes, and the precision with which data points are captured.", "There is no clear specification of Detail for its estimation in the literature. Nevertheless, purely technical accuracy consideration could imply how finely data is broken down or how much descriptive information is captured in each data point. Then Key Aspects of Data incorporate are:\nGranularity: The extent to which data is broken down into smaller, specific components. High granularity means more detailed data.\nDescriptive Attributes: The number of attributes or fields that describe an entity or event. More detailed datasets have a larger number of attributes that provide rich, descriptive context.\nPrecision: How exact the data is. For numerical data, this might refer to how many decimal points are included, for temporal data, the description of timestamps, while for categorical data, it refers to the specificity of categories."
Differential Privacy, "[]", "[\"Data Governance and Compliance\"]", "Same as Inferential Privacy, but in the opposite direction (Check for Inferential Privacy).", "Same as Inferential Privacy, but in the opposite direction (Check for Inferential Privacy). Also as defined in [TODO: Broken reference], a metric used to gauge the level of privacy preserved in data when shared or sold in marketplaces. Also, the (ϵ, δ)-differential privacy is a widely adopted concept to quantify the privacy loss in private machine learning (ML) algorithms."
Discoverability, "['Effectiveness (Platform), \"Platform Performance\"]", "[\"Innovation and Growth\"]", "Discoverability measures how easily a dataset or platform allows users to find relevant information, focusing on the effectiveness of search functionality and the dataset’s ability to meet users’ informational needs.", "As defined in [34], this is a metric that describes the ability of a dataset to show the content of information and be able to search or discover datasets. For a platform, measures the platform's ability to meet the user's information needs accurately. This KPI evaluates how effective the search functionality is in returning relevant datasets based on user input."
Space Cost, "[\"Disk Occupation\"]", "[\"Data Valuation Techniques\"]", "Space Cost refers to the amount of storage required to retain data, influenced by file format and storage mechanisms, and can be tied to the ongoing costs of maintaining that data.", "Space Cost refers to the amount of storage space required to store data, which can vary depending on the file format and storage mechanisms used. The cost can be linked later on the cost associated to maintain such information."
Downloads, "[\"Download Frequency\"]", "[\"Customer Needs and Satisfaction\", \"Market Penetration\"]", "The number of times users have dowloaded a dataset.", "The number of times users have dowloaded a dataset."
Economic Efficiency, "[\"Data Business Characteric Index\", \"Business Criticality\"]", "[\"Data Monetization\"]", "Economic Efficiency / Business Criticality is an index that evaluates the importance of data to business operations by weighting its relevance to key processes, while also ensuring that the application of data quality measures yields benefits that justify their associated costs.", "This index represents how critical the data is for business processes. It is determined by assigning weights to data based on its relevance to various operational requirements, with higher-weighted data indicating greater business importance. Economic efficiency can also refers to the cost-benefit balance when applying data quality metrics (i.e. another operation). The requirement of economic efficiency, labeled as \"Requirement\", ensures that the use of data quality metrics must justify the costs involved, meaning the benefits obtained from improved data quality should outweigh the costs of measuring and improving that quality."
Encryption Time, "[\"ET\", \"Decryption Time\", \"DT\"]", "[\"Operational Efficiency\"]", "Measures the time taken to convert plaintext data into an encrypted format using encryption algorithms.", "This metric measures the time taken to convert plaintext data into an encrypted format using encryption algorithms. It's important in cloud and data security to understand how quickly data can be secured before transmission or storage."
Energy Efficiency, "[\"Power to Performance Effectiveness\", \"PPE\", \"Power Usage Effectiveness\", \"PUE\", \"Data Centre Infrastructure Efficiency\", \"DCiE\", \"Data Centre Performance per Energy\", \"DPPE\", \"Data Centre Energy Productivity\", \"DCEP\", \"Communication Network Energy Efficiency\", \"CNEE\", \"Network Power Usage Effectiveness\", \"NPUE\", \"Energy Proportionality Coefficient\", \"EPC\"]", "[\"Operational Efficiency\"]", "Energy Efficiency Metrics for Data Centers assess how effectively energy is utilized relative to performance outputs, combining ratios like PUE, DCiE, DCEP, PPE, CNEE, NPUE, and EPC to provide a comprehensive view of how well IT equipment, networks, and infrastructure convert power into useful computational work.", "Measures how efficiently the system handles workloads concerning energy consumption. This ratio is a key metric for operational efficiency. The PUE Measures the energy efficiency of a data center by comparing the total facility energy to the energy used by IT equipment. The DCiE is the inverse of PUE, used to measure the ratio of IT equipment energy to the total facility energy. Developed by Japan's Green IT Promotion Council, the Data Cetnre Perfromance per Energy metric combines four sub-metrics: Green Energy Consumption (GEC), Power Usage Effectiveness (PUE), IT Equipment Energy Efficiency (ITEE), and IT Equipment Utilization (ITEU). It provides a holistic view of the energy efficiency of data centers, factoring in both facility and IT equipment performance. Similarly, Power to Performance Effectiveness (PPE) is a metric that evaluates the efficiency of energy consumption in relation to the performance output of IT equipment within a data center. Specifically, PPE measures how much power is consumed to achieve a certain level of performance. DCEP: This metric measures the productivity of a data center relative to the energy it consumes. It evaluates how much useful work (e.g., computational tasks, data processing) is accomplished per unit of energy consumed. Communication Network Energy Efficiency (CNEE) is a metric that evaluates the energy efficiency of a data center's communication network. It measures the amount of energy required to deliver a unit of data (usually a bit or byte) across the network within a data center. NPUE: This is a more specific metric that focuses on the energy consumed by the networking components of the data center. EPC: evaluates how well the energy consumption of individual devices or systems (such as servers, networking devices, or storage systems) scales with their workload. In an ideal scenario, a system with high EPC would use energy proportionally to its workload, consuming minimal energy when under low or no load."
Power Usage Efficiency, "[\"Total Energy Usage Effectiveness\", \"TUE\", \"Data Center Efficiency\", \"DCE\"]", "[\"Operational Efficiency\"]", "TODO", "TODO: WHAT IS THE DIFFERENCE WITH THE PREVIOUS ONE?!"
Total Equipment Utilization, "[\"TEU\"]", "[\"Operational Efficiency\"]", "TODO", "TODO: needs more explation. Encompasses the overall facility's resource usage. It includes cooling, power distribution, and other supporting infrastructure components. "
IT Equipment Utilization, "[\"ITEU\"]", "[\"Operational Efficiency\"]", "TODO", "The ITEU metric focuses on the ratio of actual energy consumption to the rated energy consumption of IT equipment, providing insight into the energy utilization efficiency of the IT infrastructure. TODO: maybe more detail?"
IT Equipment Energy Efficiency, "[\"ITEE\"]", "[\"Operational Efficiency\"]", "TODO", "TODO: missing explanation here, same as the previous one."
Data Center Performance Per Energy, "[\"DPPE\"]", "[\"Operational Efficiency\"]", "TODO", "TODO: Again, seems to be already included in Energy Efficiency."
Energy Reuse Fraction, "[\"ERF\", \"Energy Reuse Effectiveness\", \"ERE\"]", "[\"Operational Efficiency\"]", "The ERF, defined in ISO/IEC 30134-6 / EN 50600-4-6, determines the share of the total energy consumption that is reused.", "The ERF, defined in ISO/IEC 30134-6 / EN 50600-4-6, determines the share of the total energy consumption that is reused."
Power Usage Effectiveness, "[\"PUE\"]", "[\"Operational Efficiency\"]", "TODO", "TODO: same description as CUE"
Power Density Efficiency, "[\"PDE\"]", "[\"Operational Efficiency\"]", "Power Density Efficiency (PDE) is a refinement of traditional PUE metrics that evaluates the energy efficiency improvements resulting from physical changes within IT racks, offering insights into both IT equipment and cooling system performance.", "A variation of the PUE metric, called power density efficiency (PDE), that can provide insight into the improvements to both the IT equipment and the supporting cooling system. The proposed metric enables evaluation of the impact of physical changes inside the racks on energy efficiency, which is not possible using the common metrics above TODO: Above what? Provide example instead."
Water Usage Effectiveness, "[\"WUE\"]", "[\"Operational Efficiency\"]", "Assesses the water efficiency of data centers. It measures the amount of water a data center uses in relation to the energy consumed by its IT equipment.", "Assesses the water efficiency of data centers. It measures the amount of water a data center uses in relation to the energy consumed by its IT equipment."
Energy ExpenseS, "[\"EES\"]", "[\"Operational Efficiency\"]", "Quantifies how the Energy ExpenseS have been altered (i.e. increased or decreased) compared to a baseline scenario after the equipment is upgraded or the introduction of flexibility mechanisms.", "Quantifies how the Energy ExpenseS have been altered (i.e. increased or decreased) compared to a baseline scenario after the equipment is upgraded or the introduction of flexibility mechanisms."
IT Power Usage Effectiveness, "[\"ITUE\"]", "[\"Operational Efficiency\"]", "The ITUE is a PUE-type metric for the IT equipment rather than for the data center.", "The ITUE is a PUE-type metric for the IT equipment rather than for the data center."
TUE, "[\"TODO: replace with the real name\"]", "[\"Operational Efficiency\"]", "Total Energy of the data centre divided by the total energy into the computational components (as defined in ITUE).", "Total Energy of the data centre divided by the total energy into the computational components (as defined in ITUE). TODO: needs a better explanation."
Data Center Productivity, "[\"DCP\"]", "[\"Operational Efficiency\"]", "Data Center Productivity (DCP) is a metric that assesses how effectively a data center transforms consumed energy into meaningful computational output, focusing on performance per energy used rather than just energy distribution.", "Metric that evaluates how effectively a data center converts its consumed energy into useful computational work. Unlike efficiency metrics like PUE, which focus on energy distribution, DCP emphasizes the actual output or performance of a data center in relation to its energy consumption in an area or general components."
Compute Power Efficiency, "[\"CPE\"]", "[\"Operational Efficiency\"]", "Metric that assesses the efficiency of IT equipment in a data center by measuring how much of the total power consumption is effectively used for computation. ", "Metric that assesses the efficiency of IT equipment in a data center by measuring how much of the total power consumption is effectively used for computation."
Green Energy Coefficient, "[\"GEC\"]", "[\"Operational Efficiency\"]", "Metric that quantifies the proportion of energy used in a data center that comes from renewable energy sources. It is used to assess the sustainability and environmental impact of data center operations.", "Metric that quantifies the proportion of energy used in a data center that comes from renewable energy sources. It is used to assess the sustainability and environmental impact of data center operations."
Performance per Watt, "[\"PpW\"]", "[\"Operational Efficiency\"]", "The PpW metric measures the actual energy efficiency of every device in the data center and how it is used.", "The PpW metric measures the actual energy efficiency of every device in the data center and how it is used."
"Space, Wattage, and Performance", "[\"SWaP\"]", "[\"Operational Efficiency\"]", "Metric used to evaluate the efficiency of a system by considering its performance output relative to the space and power it consumes.", "Metric used to evaluate the efficiency of a system by considering its performance output relative to the space and power it consumes."
Data Center Energy Productivity, "[\"DCeP\"]", "[\"Operational Efficiency\"]", "Data Center energy Productivity (DCeP) quantifies the amount of useful work produced by a data center (or individual IT equipment) relative to the energy it consumes, treating the data center as a black box where energy input is measured against computational output.", "The DCeP essentially defines the datacenter as a blackbox — power goes into the box, heat comes out, data goes into and out of the black box, and a net amount of usefulwork is done by the black box. In other words, quantifies useful work compared to the energy it requires. It can be calculated for an individual IT device or a cluster of computing equipment."
Data Center Performance Efficiency, "[\"DCPE\"]", "[\"Operational Efficiency\"]", "Metric used to evaluate how effectively a data center utilizes energy to perform useful work.", "Metric used to evaluate how effectively a data center utilizes energy to perform useful work."
AEUF, "[\"TODO: Add the actual name\"]", "[\"Operational Efficiency\"]", "Metric used to assess how effectively a data center employs its airside economizer system for 'free' cooling.", "Metric used to assess how effectively a data center employs its airside economizer system for 'free' cooling."
Data Center Lighting Density, "[\"DCLD\", \"Lighting Power Density\", \"LPD\"]", "[\"Operational Efficiency\"]", "Measures the electrical power used for lighting per unit area within a data center, typically expressed in watts per square foot (W/ft²) or watts per square meter (W/m²). This metric helps assess the energy efficiency of the lighting system in the facility.", "Measures the electrical power used for lighting per unit area within a data center, typically expressed in watts per square foot (W/ft²) or watts per square meter (W/m²). This metric helps assess the energy efficiency of the lighting system in the facility."
Corporate Average Data Center Efficiency, "[\"CADE\"]", "[\"Operational Efficiency\"]", "Corporate Average Data Efficiency (CADE) is a metric that assesses a corporation's overall data center energy performance by integrating both infrastructure efficiency and IT asset utilization, enabling comparisons across multiple data centers.", "CADE is designed to provide a comprehensive assessment of a corporation's data center energy performance by considering both infrastructure efficiency and IT asset utilization. CADE allows the calculation and measurement of a data center's energy consumption so that it can be compared to the other data centers."
Airflow Efficiency, "[\"AFE\"]", "[\"Operational Efficiency\"]", "Airflow Efficiency measures how effectively a data center's cooling system delivers cool air to IT equipment and removes hot air, aiming to minimize air mixing and optimize energy-efficient cooling performance.", "Airflow Efficiency in the context of data centres refers to the effectiveness with which cool air is delivered to IT equipment and hot air is removed, minimizing mixing and optimizing cooling performance. High airflow efficiency means that the cooling system is well-aligned with the airflow paths, reducing energy use and ensuring reliable equipment operation."
Data Center Power Density, "[\"DCPD\"]", "[\"Operational Efficiency\"]", "Metric used to measure how much power is consumed per rack in a data center. It helps data center operators assess how efficiently they are utilizing their rack space and power capacity.", "Metric used to measure how much power is consumed per rack in a data center. It helps data center operators assess how efficiently they are utilizing their rack space and power capacity."
Server Compute Efficiency, "[\"ScE\"]", "[\"Operational Efficiency\"]", "Server Compute Efficiency (ScE) evaluates how effectively servers in a data center perform computational tasks relative to the energy they consume, providing insight into the energy-performance balance of compute resources.", "Designed to assess the efficiency of compute resources within a data center. While the specific formula for ScE isn't explicitly detailed in the available sources, the metric aims to evaluate how effectively servers perform computational tasks relative to the energy they consume. TODO: isn't that the exact same as DceP or DCPE?"
Data Center Compute Efficiency, "[\"DCcE\"]", "[\"Operational Efficiency\"]", "TODO", "Assesses the efficiency of computing resources within a data center. It provides insights into how effectively the data center's IT equipment is utilized to perform computational tasks relative to the energy consumed. TODO: Again, seems to be the same as some previous metrics. Either the explanation isn't detailed enough, or this should be merged."
Data Center Workload Power Efficiency, "[\"DWPE\"]", "[\"Operational Efficiency\"]", "TODO", "Bridges the gap between infrastructure-level and workload-level energy efficiency. TODO: needs more explanation."
Deployed Hardware Utilization Efficiency, "[\"DHUE\"]", "[\"Operational Efficiency\"]", "Measures the efficiency of deployed servers by comparing the minimum number of servers required to handle peak compute load to the total number of servers deployed.", "Measures the efficiency of deployed servers by comparing the minimum number of servers required to handle peak compute load to the total number of servers deployed."
Deployed Hardware Utilization Ratio, "[\"DHUR\"]", "[\"Operational Efficiency\"]", "TODO", "Evaluates the proportion of active servers running live applications relative to the total number of servers deployed. TODO: Probably needs a better explanation to differentiate it from the previous metric."'
Cooling Capacity Factor, "[\"CCF\"]", "[\"Operational Efficiency\"]", "Assesses the utilization efficiency of the cooling infrastructure.", "Assesses the utilization efficiency of the cooling infrastructure. TODO: very fuzzy explanation, needs improvement."
Adaptability Power Curve, "[\"APC\", \"Adaptation of Data Center to Available Renewable Energy\", \"APCren\"]", "[\"Operational Efficiency\"]", "Quantifies how much a data center's actual power usage deviates from its baseline profile over time, while APCren extends this by assessing the impact of renewable energy sources on that deviation.", "Measures the adaptability of a data center's power consumption by quantifying the deviation of actual monitored power from the baseline power profile over a given time interval. Similarly, APCren can be seen as a modified version that loks for the renewable energy sources influences."
The Green Index, "[\"TGI\"]", "[\"Operational Efficiency\"]", "This metric offers flexible green benchmarking, allowing diverse user interpretations. While defined using performance-per-watt, it can incorporate any energy-efficiency metric. TGI focuses primarily on IT equipment power but can be extended to include cooling infrastructure.", "This metric offers flexible green benchmarking, allowing diverse user interpretations. While defined using performance-per-watt, it can incorporate any energy-efficiency metric. TGI focuses primarily on IT equipment power but can be extended to include cooling infrastructure."
Data Center Space Efficiency, "[\"DCSE\"]", "[\"Operational Efficiency\"]", "Assesses how effectively a data center utilizes its available physical space. Efficient space utilization is crucial for optimizing operational costs, energy consumption, and overall performance.", "Assesses how effectively a data center utilizes its available physical space. Efficient space utilization is crucial for optimizing operational costs, energy consumption, and overall performance."
Delta-T Per Cabinet, "[\"Temperature Per Cabinet\", \"T Per Cabinet\"]", "[\"Operational Efficiency\"]", "Delta-T (ΔT) and Temperature per Cabinet are thermal efficiency metrics that measure the temperature difference between incoming and outgoing air in a server cabinet, providing key insights into the effectiveness of cooling systems at the individual cabinet level.", "Temperature difference between the air entering and exiting an individual server cabinet. This metric is crucial for assessing the effectiveness of cooling systems and ensuring optimal equipment performance. Similarly, Temperature per Cabinet serves as a critical metric for assessing thermal conditions at the individual cabinet level. Given its connection to Delta-T, it is aggregated here."
Fixed to Variable Energy Ratio, "[\"FVER\", \"Data Center FVER\", \"DC-FVER\"]", "[\"Operational Efficiency\"]", "Metric designed to assess the proportion of fixed (constant) energy consumption relative to variable (dynamic) energy consumption.", "Metric designed to assess the proportion of fixed (constant) energy consumption relative to variable (dynamic) energy consumption."
Grid Utilization Factor, "[\"GUF\"]", "[\"Operational Efficiency\"]", "Metric used to assess the extent to which a data center relies on power from the electrical grid versus on-site power generation.", "Metric used to assess the extent to which a data center relies on power from the electrical grid versus on-site power generation."
Electronics Disposal Efficiency, "[\"EDE\"]", "[\"Operational Efficiency\"]", "Assesses the disposal of decommissioned Information and Communication Technology (ICT) assets.", "Assesses the disposal of decommissioned Information and Communication Technology (ICT) assets."
TODO:Missing Name, "[]", "[\"Operational Efficiency\"]", "Quantifies the proportion of energy in a data center that does not directly contribute to IT operations.", "Quantifies the proportion of energy in a data center that does not directly contribute to IT operations."
HVAC System Effectiveness, "[\"HSE\"]", "[\"Operational Efficiency\"]", "TODO", "Measures the overall efficiency of a data center's cooling system. TODO: Needs a better explanation, feels redundant with Airflow Efficiency"
Stranded Power Capacity Per Rack, "[\"SPCR\"]", "[\"Operational Efficiency\"]", "Allocated but unused power within individual server racks.", "Allocated but unused power within individual server racks."
UPC Metrics, "[\"USF\", \"UCF\", \"UPFC\", \"UPF\", \"UPEE\", \"TODO: What are all these acronyms?!\"]", "[\"Operational Efficiency\"]", "", "Metrics related to the performance of Uninterruptible Power Supply. These metrics are general energy efficiency or performance metrics related to that unit, such as Energy Efficiency (UPEE), which measure how UPS converts input power into usable output power while minimizing energy losses. TODO: Again, feels redundant with DCPE."
"Availability, Capacity, and Efficiency", "[\"ACE\"]", "[\"Operational Efficiency\"]", "TODO", "In the context of Heating, Ventilation, and Air Conditioning (HVAC) systems, performance is often evaluated based on metrics such as Availability, Capacity, and Efficiency. General Expression can be used to track ACE. TODO: What is general expression? + this explation explains absolutely nothing haha"
Energy Data Center, "[\"EDC\"]", "[\"Operational Efficiency\"]", "Total energy consumption of a data center, encompassing both IT hardware energy usage and supporting infrastructure.", "Total energy consumption of a data center, encompassing both IT hardware energy usage and supporting infrastructure."
Other Utilities, "[]", "[\"Operational Efficiency\"]", "TODO", "Given the broadness of operational units, other more specific metrics have been grouped as Other Utilities. These include metrics such as those for Thermal and Air management. HVAC (Heating, Ventilation, and Air Conditioning) is crucial for maintaining optimal operating conditions for IT equipment. The documents mention several metrics related to HVAC performance, which are key to evaluating the energy efficiency of HVAC systems. Here includes the RCI, Airflow efficiency, and cooling system efficiency. The Recirculation Index (RI) is a metric used in data center airflow management to quantify the extent of hot air recirculation within the facility. It helps measure how much of the warm air from IT equipment exhaust is recirculated back into the system instead of being expelled or effectively cooled. The Capture Index (CI) is a metric used in data center airflow management to measure how effectively the cooling system is capturing and directing the hot exhaust air from IT equipment into the return air path (i.e., the cooling intake) without mixing with the cold air supply. Data Centre Cooling System Efficiency (DCCSE) is a metric used to measure the efficiency of the cooling systems in a data center. It evaluates the ratio of the power consumed by the cooling infrastructure to the total IT load in the data center. TODO: This text is a mess and cannot be used as is for the website."
Renewable Energy Factor, "[\"REF\", \"On-site Energy Fraction\", \"OEF\", On-site Energy Matching', \"OEM\"]", "[\"Operational Efficiency\"]", "Renewable Energy Fraction (REF), On-site Energy Fraction (OEF), and On-site Energy Matching (OEM) are metrics that evaluate a data center's sustainability by measuring the use and alignment of renewable energy sources—respectively assessing total renewable usage, the portion generated on-site, and how well on-site generation matches energy consumption patterns.", "REF measures the proportion of a data center's total energy consumption that is sourced from renewable energy. OEF evaluates the share of a data center's energy needs met through on-site renewable energy generation. OEM assesses how well the on-site renewable energy generation aligns with the data center's energy consumption patterns."
Entropy, "['Shannon's Entropy', \"Heterogeneity\", \"Information Entropy\", \"Additional Information Value\", \"AIV\", \"Joint Entropy\", \"Individual Entropy\", \"Information Score\", \"Conditional Entropy\"]", "[\"Data Quality\"]", "Entropy-based metrics quantify the uncertainty or information content in data, with applications including spatial/temporal diversity, and variants like Additional Information Value (AIV), joint entropy, and conditional entropy assessing information gain, combined uncertainty, and remaining unpredictability given known variables.", "Entropy measures the uncertainty or randomness in a dataset, quantifying the amount of information or degree of surprise. Examples include evaluating spatial and temporal diversity in data for tasks like travel time prediction. Additional Information Value (AIV) gauges the value added by entropy reduction when transforming raw data. Joint entropy measures total uncertainty of two variables, and conditional entropy quantifies remaining uncertainty in one variable given another."
Error Rate, "[\"Error Ratio\", \"Error Count\", \"Failure Rate\", \"Uplink/Downlink Error Rate\", \"Number of Trouble Tickets\", \"Interserver Error Rate\", \"ISER\"]", "[\"Operational Efficiency\"]", "Error rate (also known as failure rate or linked to trouble tickets) quantifies the proportion of failed operations within a system, network, or process over time.", "Error rate (also known as failure rate or linked to trouble tickets) quantifies the proportion of failed operations within a system, network, or process over time. It is a key metric in service reliability, communication networks, machine learning, databases, and cloud computing to assess stability and efficiency."
Annual Fraction of Data Loss, "[\"AFDL\"]", "[\"Data Quality\"]", "Measures the fraction of stored data lost annually, assessing reliability in distributed systems.", "Measures the fraction of stored data lost annually, assessing reliability in distributed systems."
Response Time, "[]", "[\"Operational Efficiency\"]", "Total duration from the initiation of a request to the system's response. It encompasses multiple factors such as processing time, communication latency, database access latency, transaction processing speed, and network-induced delays.", "Total duration from the initiation of a request to the system's response. It encompasses multiple factors such as processing time, communication latency, database access latency, transaction processing speed, and network-induced delays."
Elapsed Time, "[]", "[\"Operational Efficiency\"]", "TODO", "Total time taken to complete an operation. TODO: Isn't this redundant with the previous one?"
Extensibility, "[]", "[\"Innovation and Growth\"]", "Refers to the ability to add new features or devices without disrupting existing systems, linked to scalability.", "Refers to the ability to add new features or devices without disrupting existing systems, linked to scalability."
FAIRness Score, "[]", "[\"Data Quality\"]", "", "FAIRness Score evaluates datasets' compliance with the FAIR principles. TODO: Provide a short explanation of the FAIR principles."
Shapley Fairness, "[\"Fairness Metrics\"]", "[\"Data Quality\"]", "TODO", "Related to allocating resources proportionally in systems like VMs or ensuring data fairness, e.g., reducing biases. TODO: These two things seem completely unrelated, this needs a better explanation. Example: Shapley Fairness refers to a method of fairly attributing the contribution of each feature or participant in a model or system based on Shapley values, which come from cooperative game theory. It ensures that each contributor's impact is evaluated considering all possible combinations, leading to a balanced and equitable distribution of credit or importance."
Format, "[\"Format Compliance\", \"Codification\", \"Conformity\", \"Avaialble Formats\", \"Conformity Rate\"]", "[\"Operational Efficiency\"]", "Measures adherence to specified data formats to ensure data structure and quality, often calculated as conformity rate.", "Measures adherence to specified data formats to ensure data structure and quality, often calculated as conformity rate."
User Frequency, "[\"User Count\", \"Concurrent Users\"]", "[\"Customer Needs and Satisfaction\", \"Market Penetration\"]", "TODO", "Tracks the number of concurrent users accessing data, with an associated cost for each additional user. TODO: Cost in the explanation doesn't seem to fit the name here."
Access Frequency, "[\"Number of Requests\", \"Arrival Rate\", \"Access Interval\", \"Number of Accesses\", \"Usage over Time\"]", "[\"Customer Needs and Satisfaction\", \"Market Penetration\"]", "Total count of operations, transactions, or queries made to a system within a given period.", "Total count of operations, transactions, or queries made to a system within a given period. Measures the overall demand for platform content, capturing the number of times datasets, services, or features are accessed, irrespective of whether by single or multiple users. TODO: Fix the table here."
Granularity, "[\"Data Frequency\", \"Abundance\"]", "[\"Data Quality\"]", "Granularity refers to the level of detail or precision of the data.", "Granularity, in the context of data management and analysis, refers to the level of detail or precision of the data being collected, stored, and analyzed (or space between time stamps for dynamic data). It indicates how finely data is broken down into its components and can significantly impact the quality and usefulness of the data for various applications."
Velocity, "[\"Frequency Parameters\"]", "[\"Data Quality\"]", "TODO", "TODO: It has the same explanation as the previous one."
Hop Distance, "[\"Uplink/Downlink Hop Distance\", \"UDHD\", \"Interserver Hop Distance\", \"ISHD\"]", "[\"Operational Efficiency\"]", "Measures the number of intermediate devices data traverses in a network, affecting efficiency and latency.", "Measures the number of intermediate devices data traverses in a network, affecting efficiency and latency."
Inclusiveness, "[]", "[\"Innovation and Growth\"]", "Inclusiveness as a KPI measures how well a strategy or system enables diverse stakeholder participation and contribution, balancing broad engagement with quality to enhance innovation, decision-making, and value creation.", "Inclusiveness as a Key Performance Indicator (KPI) evaluates how effectively a strategy or data approach enables participation and contribution from diverse and valuable stakeholders while achieving critical objectives. It emphasizes incorporating a wide array of inputs, perspectives, or participants to maximize value creation without compromising quality or performance.\nThe benefits of Inclusiveness as a KPI includes:\nDiversity of Input and Innovation: Measuring inclusiveness ensures capturing diverse viewpoints and stakeholder inputs, leading to better decision-making, innovative solutions, and improved outcomes.\n Stakeholder Engagement: High inclusiveness fosters stakeholder involvement, enhancing relationships, loyalty, and buy-in from participants such as customers, employees, or partners.\nQuality and Participation Balance: Balances broad participation with maintaining performance quality, ensuring contributions are valuable and not detrimental to objectives."
Inferential Privacy, "[]", "[\"Data Governance and Compliance\"]", "Ensures that even with observed data, the adversary's ability to infer private information is significantly limited.", "Quantifies the probability that an adversary can correctly infer a private parameter (denoted as θ) from observable data (denoted as Y). It aims to ensure that even with observed data, the adversary's ability to infer private information is significantly limited. TODO: Probably needs a better explanation."
Information Content, "[]", "[\"Data Quality\"]", "Information Content quantifies the amount of unique or novel information in each data packet.", "Information Content quantifies the amount of unique or novel information in each data packet. It is based on the probability of an event captured by the packet, where less probable (more unique) events hold higher information content. Data packets with low redundancy, often representing unexpected or rare events, have a higher IC value, making them more valuable for real-time and relevant data applications."
Information Diffusion, "[\"Data Distribution\", \"Information Distribution\"]", "[\"Innovation and Growth\"]", "Information Diffusion measures how effectively and broadly information flows across people, organizations, or systems, influenced by factors like scarcity, sharing practices, technological infrastructure, and communication channels.", "Addresses the flow of information across various entities, such as individuals, organizations, or systems, and how effectively, quickly, or broadly it can be shared or accessed. Key Components: \nScarcity: The availability or rarity of the information; scarce information is less likely to spread widely.\nSharing: The extent to which information is openly shared or kept private. Open data and social sharing platforms promote wider diffusion (i.e. linked to data governance).\nInfrastructure: The technological systems and networks (e.g., databases, cloud systems) that enable information transfer.\nChannels: The media or platforms (e.g., email, social media, enterprise systems) through which information flows, is presented, or advertised."
Integrity, "[\"Reliability\", \"Data Prevention\", \"Data Source Corroboration\"]", "[\"Data Quality\"]", "Data Integrity ensures data remains accurate, consistent, and reliable throughout its lifecycle, safeguarding it from unauthorized changes or corruption to support trustworthy decision-making and operations.", "Data integrity refers to the accuracy, consistency, and reliability of data throughout its lifecycle, ensuring that it remains correct, unaltered, and preserved from unauthorized access or corruption. Maintaining data integrity is crucial for ensuring the data is trustworthy and useful for decision-making, analysis, and operations."
EAFDL, "[\"TODO: change to real name\"]", "[\"Data Quality\"]", "TODO", "EAFDL measures annual data loss as a fraction of total stored data. TODO: Same definition as AFDL."
Internal Rate of Return, "[\"IRR\"]", "[\"Data Monetization\"]", "Internal Rate of Return (IRR) is the annualized discount rate that makes the net present value (NPV) of an investment's cash flows equal to zero, indicating the investment's expected profitability.", "Internal Rate of Return (IRR) is a financial metric used to evaluate the profitability of an investment. It represents the annualized rate of return that makes the net present value (NPV) of all cash flows (both incoming and outgoing) equal to zero. In other words, IRR is the discount rate at which the present value of an investment's costs equals the present value of its benefits. "
Interoperability, "['Compatibibility, \"Integration Capabilities\"]", "[\"Operational Efficiency\"]", "TODO", "Interoperability refers to the ability of different systems, applications, or dataset to seamessly be integrated. It ensures that data can be shared, understood, and utilized across various platforms and environments.Key Aspects to estimate is as a metric or KPI include Concordance of Data Quality aspects and Governance factors (e.g. same Granularity or similar to a settled standard or Schema), TODO: Poor explanation, needs corrections."
Latency, "['Uplink/Downlink Communication Latency, \"UDCL\", \"Interserver Communication Latency\", \"Database Access Latency\", \"Transaction Finality Time\"]", "[\"Operational Efficiency\"]", "TODO", "Latency measures the delay between the time a request is made and the time a response is received, typically measured in milliseconds (ms). It can also refer to the time it takes for a system to respond to a service (e.g., transaction finality time as noted in [15]). TODO: Similar to Response Time."
Learnability (User), "[]", "[\"Customer Needs and Satisfaction\"]", "Learnability measures how easily users, especially new ones, can understand and use a platform to perform tasks like data search and visualization, typically assessed through user testing.", "Assesses how easily users can learn to use the platform and perform tasks such as data search and visualization. Learnability is evaluated based on user testing results, focusing on how simple and understandable the data and interface are for new users."
Leave-One-Out, "[\"LOO\"]", "[\"Data Valuation Techniques\"]", "Leave-One-Out (LOO) Value estimates the value of a specific data source by measuring the change in model performance — typically prediction accuracy — when that source is removed from the training data.", "A method for estimating the data value by measuring the difference in performance when a specific data source is different. The LOO value is calculated by comparing the prediction accuracy of a model trained with and without the specific data source."
Licensing, "[\"License Compliance\", \"Free License\", \"Licensing Restrictions\"]", "[\"Data Governance and Compliance\"]", "", "Measures the proportion of datasets published under specific licensing terms, such as open licenses (e.g. Datenlizenz Deutschland Zero, or Creative Commons)."
Lifecycle, "[\"Shelf Life of Data\"]", "[\"Innovation and Growth\"]", "", "The lifecycle refers to the length of time a source of information is expected to remain active. Information is perishable, and after the lifecycle ends, the node (source of information) is assumed to no longer generate value."
Location Yardstick Score, "[]", "[\"Data Valuation Techniques\"]", "A metric to measure the contextual value of location data based on its contribution to specific analytical tasks, such as trajectory estimation.", "A metric to measure the contextual value of location data based on its contribution to specific analytical tasks, such as trajectory estimation."
Loss and Missed Opportunity Costs, "[\"Data Root Cause Remediation\"]", "[\"Data Valuation Techniques\"]", "Corresponds to revenues and profits lost due to poor data quality.", "Corresponds to revenues and profits lost due to poor data quality. For instance, inaccurate customer email addresses can result in lower revenues as acquired customers cannot be reached for advertising campaigns."
Replacement Cost, "[\"Loss of Information Value\", \"LIV\", \"Revenue Loss\"]", "[\"Data Valuation Techniques\"]", "Metric quantifying the financial impact of losing or compromising information, encompassing both the cost of reacquiring or replacing the information and the cumulative income lost over time due to its unavailability.", "Metric quantifying the financial impact of losing or compromising information, encompassing both the cost of reacquiring or replacing the information and the cumulative income lost over time due to its unavailability."
Maintainability, "[]", "[\"Operational Efficiency\"]", "Maintainability measures the ease with which data systems and datasets can be managed, updated, and improved over time, emphasizing modularity, scalability, error handling, automation, and clear documentation to support long-term system adaptability.", "Maintainability evaluates how easily data systems, databases, and datasets can be managed, updated, cleaned, and enhanced over time. It involves modularity, scalability, ease of updates, error management, documentation, automation, and adaptability."
Operational Expenditures, "[\"Operating Expenses\", \"OPEX\", \"Operational Cost\", \"Maintenance Cost\", \"System Cost\", \"Storage Cost\", \"Contractual Costs\", \"Labour Costs\", \"Utility Costs\", \"Transaction Fees\", \"Publishing Cost\", \"Service Cost\", \"Application Cost\", \"Cost\"]", "[\"Data Monetization\"]", "Operational Expenditure (OPEX) encompasses the recurring costs of running data systems and data centers, including expenses for storage, maintenance, security, data management, compliance, labor, utilities, and third-party services—critical for sustaining performance, legal compliance, and profitability in data-driven operations.", "OPEX refers to the ongoing, day-to-day expenses incurred by an organization in the normal course of operations. These are recurring costs necessary for running the business. Operational Costs include expenses for storing, organizing, backing up, securing, and updating data to ensure its usability and relevance. Specific costs vary based on dataset size, tools, and organizational needs. Furthermore, for a data centre, these costs can include hardware maintenance, and different contractual costs. In the context of data monetization, contractual costs are fixed expenses paid to third-party contractors or service providers for activities like data processing, analysis, or infrastructure. These may include cost-plus clauses, such as charges based on data volume or time-related expenses for ongoing services. While these costs often represent the main expense for a decision node, additional overheads may exist, especially when contractors work on-site. Managing these costs is essential to ensure profitability in data monetization efforts. \nMaintenance costs for data (not data centres) can include various aspects:\nStorage Costs: This involves expenses related to storing the data, such as cloud storage fees or physical hardware costs.\nData Management: Costs associated with organizing, indexing, and ensuring the data remains accessible and usable. This might involve using data management tools or hiring personnel for these tasks. Backup and Recovery: Regularly backing up data and having a disaster recovery plan can be costly, especially for large volumes of data.\nSecurity: Implementing and maintaining security measures to protect data from breaches, loss, or corruption can be significant.\nData Cleansing and Updating: Regularly updating and cleaning data to maintain its accuracy and relevance can incur costs, particularly if it involves manual processes or sophisticated software. Compliance and Legal: Ensuring that data management practices comply with regulations (like GDPR or HIPAA) may require legal and administrative resources.\nPerformance and Optimization: Costs related to optimizing data systems for performance, including upgrading hardware or software.\nThe specific costs can vary widely depending on the size of the dataset, the tools and technologies used, and the organizational needs. \nIn term of Labour Costs, there are both direct and indirect labour costs associated with Big Data and information processing in general. These could include: \Hardware installation costs.\nSalaries/Wages for collecting, processing analyzing, troubleshooting, or all system functionalities required to sustain the system. \nConsulting fees. \nEmployee training costs.\nUtility costs includes all the overheads required to run the various equipment. These include electrical requirements as well as maintenance requirements, such as the cleaning of fans or sensors. \nFinally, any other miscellaneous costs should be included here as well, for instance: training material, safety gear, transportation costs, and server room and office costs (when their sole purpose is to operate the Big Data system)."
Maintenance Frequency, "[]", "[\"Operational Efficiency\"]", "The frequency with which a dataset requires maintenance, directly impacting operational costs.", "The frequency with which a dataset requires maintenance, directly impacting operational costs."
Market Adjustment Factor, "[\"Discount Price\", \"Full Price\"]", "[\"Data Monetization\"]", "A coefficient that adjusts the base market price depending on external market conditions. Reflects factors like market demand, competition, and dynamics influencing the final sale price.", "A coefficient that adjusts the base market price depending on external market conditions. Reflects factors like market demand, competition, and dynamics influencing the final sale price."
Market Value of Information, "[\"MVI\", \"Average Financial Contribution per Record\"]", "[\"Data Monetization\"]", "This metric calculates the potential income from selling, leasing, or sharing information. It incorporates time, price, exclusive price, and discount rate.", "This metric calculates the potential income from selling, leasing, or sharing information. It incorporates time, price, exclusive price, and discount rate."
Mean Time to Data Loss, "[\"MTTDL\"]", "[\"Data Quality\"]", "A traditional metric estimating how long a system will operate before experiencing data loss. Useful for comparing redundancy schemes and estimating system reliability.", "A traditional metric estimating how long a system will operate before experiencing data loss. Useful for comparing redundancy schemes and estimating system reliability."
Metadata, "[\"Contextual Information\", \"Documentation Features\", \"Profiling\"]", "[\"Data Quality\"]", "Describes the required information in detail, including preferences for format and medium.", "Describes the required information in detail, including preferences for format and medium."
Mutual Information, "[]", "[\"Data Quality\"]", "Measures the mutual dependence between two variables, quantifying the amount of information shared.", "Measures the mutual dependence between two variables, quantifying the amount of information shared. Applications include feature selection, data compression, and pricing."
NDG, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "Metric related to Traceability. Total number of simple decisions that trace up two simple goals in the goal hierarchy. TODO: needs a proper explanation and definition."
NDGI, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "TODO: needs a proper explanation."
NDI, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "TODO: needs a proper explanation."
Net Present Value, "[]", "[\"Data Monetization\"]", "TODO", "Determines the future cash flows of an asset to calculate its value. TODO: needs a proper explanation."
Network Traffic Overheard, "[]", "[\"Operational Efficiency\"]", "Measures the bandwidth and resource consumption associated with data transactions, influencing costs and scalability.", "Measures the bandwidth and resource consumption associated with data transactions, influencing costs and scalability."
NGD, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "TODO: needs a proper explanation."
NGI, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "TODO: needs a proper explanation."
NID, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "TODO: needs a proper explanation."
NIG, "[\"TODO: provide the actual name\"]", "[\"Data Governance and Compliance\"]", "TODO", "TODO: needs a proper explanation."
Traffic Energy, "[\"Management and Monitoring Traffic Energy\", \"MMTE\"]", "[\"Technology and Infrastructure\"]", "Traffic Energy Measures the total energy used during data generation, transmission, processing, and storage across a network, including sensor activity, network hops, and computational resources.", "Amount of energy consumed by a system during the transmission, processing, and storage of data across a network. This metric accounts for the power required by sensors to generate data, the energy used for data transmission across multiple network hops, and the computational resources needed to store and process incoming information. Additionally, some specific component of data management can be measured, as defined in [126]."
Traffic Ratio, "[\"Management and Monitoring Traffic Ratio\", \"MMTR\", \"Internal Traffic\", \"External Traffic\"]", "[\"Technology and Infrastructure\"]", "Traffic Ratio quantifies the share of a specific type of network traffic compared to total traffic, enabling analysis of traffic composition and aiding in performance optimization.", "Traffic Ratio is a metric that represents the proportion of a specific type of network traffic relative to the total traffic in a network or data center. It is used to analyze the composition of traffic, distinguish between different categories (e.g., internal vs. external, management vs. application-specific), and optimize network performance."
Node Value, "[\"NV\"]", "[\"Data Valuation Techniques\"]", "Node Value represents the worth of information at a specific decision point within the Decision-Based Valuation (DBV) framework, calculated based on its contribution to decision-making and the quality of data used.", "A decision node in the Decision-Based Valuation (DBV) method represents a specific point within an organization's decision-making process where information is utilized to make decisions. At each node, the information used has a distinct value, calculated by considering its contribution to the decision-making process and the quality of the data utilized."
Number of Sensitive Fields, "[]", "[\"Data Governance and Compliance\"]", "Measures the number of data columns governed by policies in a data store.", "Measures the number of data columns governed by policies in a data store."
Objectivity, "[]", "[\"Data Quality\"]", "Objectivity measures how free data and its analysis are from bias or subjective influence, ensuring reliable, valid, and replicable conclusions through consistent, evidence-based methods.", "Objectivity refers to the degree to which data and its analysis are free from bias, personal opinions, or subjective interpretations. Ensures conclusions based on data are valid, reliable, and replicable. Key aspects include unbiased data collection, consistent application of methods, and evidence-based conclusions."
Open Data Barometer, "[\"ODB\"]", "[\"Data Valuation Techniques\"]", "Open Data Barometer (ODB) is a global index that evaluates governments' use of open data across readiness, implementation, and impact to promote transparency, innovation, and societal benefit.", "The Open Data Barometer (ODB) is a global index created by the World Wide Web Foundation to measure how governments are using open data to promote transparency, innovation, and social impact. It evaluates three main areas: readiness, which looks at how prepared governments and societies are to support open data; implementation, which assesses the availability and quality of published data; and impact, which examines how open data benefits politics, the economy, and society. By combining these factors, the ODB ranks countries and highlights opportunities for improvement."
Openness, "[\"Sharing\"]", "[\"Data Governance and Compliance\"]", "Openness is a metric that assesses how freely and easily data can be accessed and reused, focusing on open licensing, accessible formats, metadata quality, and user-friendly access.", "Openness measures the degree to which datasets provide a confirmed open license and format. The metric evaluates factors like open licensing, format compatibility, metadata quality, and ease of access."
Operation Cost, "[\"Execution Cost\"]", "[\"Data Monetization\"]", "TODO", "TODO: should be included in OPEX / It is redundant"
Service Agreement, "[]", "[\"Data Governance and Compliance\"]", "", "A formal contract defining data ownership, licensing restrictions, compliance standards, and usage rights, evaluated for clarity, regulatory alignment, and flexibility to support data utility and accessibility. TODO: Needs a better explanation, feels redundant with licensing"
Ownership, "[]", "[\"Data Governance and Compliance\"]", "", "This metric evaluates the outright ownership of the dataset, including any licensing restrictions and service agreements. Ownership impacts the value of the data based on who controls it and under what terms it can be used or shared. Assessed based on licensing terms and ownership rights detailed in service agreements. TODO: Again, very similar to licensing, maybe some of them could be merged into something meaningful?"
Payment Accuracy Tradeoff, "[]", "[\"Data Valuation Techniques\"]", "Payment-Accuracy Tradeoff measures the balance between compensating individuals for their private data and the resulting accuracy of data insights, highlighting the cost required to achieve reliable analysis under privacy constraints.", "The Payment-Accuracy Tradeoff as a KPI measures the balance between the cost of compensating individuals for sharing their private data and the accuracy of the insights gained from that data. It reflects how much payment is required to achieve a desired level of accuracy in data analysis, considering the privacy constraints."
Plausibility, "[\"Credibility\", \"Believability\", \"Match Between System and the Real World\"]", "[\"Data Quality\", \"Operational Efficiency\"]", "Plausibility evaluates whether data is reasonable and credible by checking its alignment with expected patterns, relationships, or real-world logic within a given context.", "Plausibility in the context of data refers to the degree to which the data is reasonable, credible, and aligns with expectations based on known relationships, patterns, or rules. It assesses whether the data makes sense within the context it is being used, ensuring that it reflects real-world situations or follows logical assumptions."
Policy, "[]", "[\"Data Governance and Compliance\"]", "Policies are high-level principles or rules that an organization establishes to guide decision-making and behavior.", "Policies are high-level principles or rules that an organization establishes to guide decision-making and behavior. TODO: How is that a metric or a KPI?"
Precision, "[]", "[\"Data Quality\"]", "TODO", "Precision refers to the exactness or level of detail with which data is captured, measured, and represented. It describes how specific the data values are and impacts the reliability of results and analyses. TODO: I would disagree with that definition, precision is basically how detailed the data is (e.g. the number of digits provided) but has nothing to do with its exactness."
Privacy Budget, "[]", "[\"Data Governance and Compliance\"]", "The privacy budget quantifies the amount of privacy loss tolerated in a system.", "The privacy budget quantifies the amount of privacy loss tolerated in a system. It is denoted by ϵ (epsilon), which controls the trade-off between privacy and accuracy in differential privacy algorithms. A smaller ϵ provides stronger privacy guarantees at the expense of data utility. TODO: Could use more explanation with an example."
Privacy Level, "[\"Privacy Sensitivity\", \"Propensity Score\"]", "[\"Data Governance and Compliance\"]", "", "The privacy level ϵ measures the privacy risk or leakage in data reporting. It helps assess or control the trade-off between privacy, data utility, and the cost to compensate individuals for privacy loss. A lower propensity score indicates synthetic data closely resembles real data without revealing sensitive information. TODO: Also noted epsilon, last the previous one. Also, seems to be closely related to other privacy metrics."
Process Failure Costs, "[]", "[\"Data Valuation Techniques\"]", "TODO", "TODO: Needs a proper explanation, in particular a link with the Error Rate"
Processing Value Ratio, "[]", "[\"Data Valuation Techniques\"]", "TODO", "The Processing Value Ratio (Vp) (TODO: Is this acronym correct?) is described in the document as a measure used to determine the value added through processing data into information. It is calculated differently based on the type of value transfer (Type H or Type L). TODO: Not sure I understand this one. Needs a proper explanation for the website at least."
Protection Expense, "[]", "[\"Data Governance and Compliance\", \"Data Valuation Techniques\"]", "This is the estimated cost to apply protection measures (e.g., encryption, access control) to specific data stores.", "This is the estimated cost to apply protection measures (e.g., encryption, access control) to specific data stores. Includes costs of implementing security controls, maintenance, and resource allocation. Estimation can vary based on system infrastructure."
Quality Factor, "[\"QF\"]", "[\"Data Quality\"]", "TODO", "Links overall quality of information, including accuracy and frequency, to its potential value for business innovation and growth. TODO: Needs a better explanation"
Understandability, "[]", "[\"Data Quality\"]", "TODO", "Understandability is defined as a data quality dimension that measures the  extent to which a dataset or its components (e.g., field names, units, and metadata) are clear, unambiguous, and provide sufficient context to enable effective interpretation and use by the intended audience. TODO: Already defined in Clarity, needs to be merged?"
Quality of Service, "[\"QoS\", \"Data Connected to Service Levels\", \"Service Characteric Index\", \"Service Level Agreement\"]", "[\"Customer Needs and Satisfaction\"]", "Quality of Service (QoS) measures the performance and reliability of data access, focusing on latency constraints and adherence to Service Level Agreements (SLAs) for response times and availability.", "QoS refers to the performance level and reliability expected by clients when accessing datasets. Key points include latency constraints (ensuring acceptable latency for reconstructing datasets) and adherence to Service Level Agreements (SLAs), which outline expected performance metrics such as response times and availability."
Quantity of Private Projects, "[]", "[\"Innovation and Growth\"]", "TODO", "Represents the quantity of private projects/services/datasets available online. Projects are accessible, and data is public. TODO: What? Contradictory statements here."
Quantity of Public Projects, "[]", "[\"Innovation and Growth\"]", "TODO", "TODO: Same definition as previous one."
Value Range, "[]", "[\"Data Monetization\"]", "TODO", "Describes the potential value achievable using required information. This value is assessed within a range, where moderation ensures values remain within reasonable or typical limits. Based on DBV method, incorporates income approach for estimating benefits of intangible assets. TODO: Needs a better name, i was expecting something completely different from this, maybe Potential Financial Value Range?"
Range, "[]", "[\"Data Quality\"]", "TODO: This is what I was expecting for Value Range", "Range is a metric used to quantify the proportion of data values that fall within predefined lower and upper bounds, reflecting the validity of data within expected limits. TODO: I would expand this to reflect different kind of ranges (space, time, values, etc)."
Moderation, "[]", "[\"Data Quality\"]", "TODO", "Moderation is a metric that measures the proportion of data values within a 99% confidence interval, assuming a Gaussian distribution for the data. TODO: Doesn't a '99% confidence internal' always contain 99% of the data?! + that name feels weird to me, from the description, I would call it something like Typical Range or something."
Reconstruction Cost, "[\"Packet Recovery Score\"]", "[\"Data Valuation Techniques\"]", "", "Reconstruction Cost typically refers to the financial or computational resources required to rebuild or restore data, often from backups or redundant sources, after loss or corruption. It emphasizes the cost-effectiveness and feasibility of recovering critical data in systems that prioritize data availability and integrity.\nPacket Recovery Score, on the other hand, is more commonly associated with networking or communication systems. It measures the effectiveness of recovering lost or corrupted packets in data transmission. This score highlights the robustness and resilience of systems like IoT networks or wireless sensor networks against packet loss, ensuring uninterrupted operations. Packet recovery score details are in [19]. TODO: Why are these two metrics put under the same thing when they refer to two different things?"
Relevance, "[\"Decision Support Capabilities\", \"Relevance Factor\", \"Priority Score\", \"Importance\", \"Existence\"]", "[\"Data Valuation Techniques\"]", "", "Refers to the usefulness of data for business processes, ensuring data is meaningful, reusable, and adaptable to changing demands. Includes relevance factor, priority score, and existence checks for completeness. TODO: Again, that name of Relevance seems to encapsulate much more than relevance here."
Renewable Energy Factor, "[\"Green Energy Consumption\", \"GEC\", \"...\"]", "[\"Innovation and Growth\"]", "TODO", "TODO: Already described in GEC with a similar explanation. Should be merged? They both are in different categories."
Reputation, "[\"Popularity\"]", "[\"Market Penetration\"]", "", "Refers to the perceived quality, reliability, and trustworthiness of data, impacting decision-making and governance. Key aspects include quality, governance, transparency, and ethical use. Reputation can be measured using quantitative and qualitative methods, such as evaluating historical accuracy and reliability, aggregating trust scores from systems or stakeholders, using popularity as a proxy, tracking responsiveness to errors, ensuring compliance with standards, and incorporating social feedback like user ratings and endorsements. Combining these approaches provides a robust reputation score. [86]"
Responsiveness, "[\"Time Metrics\", \"Speed\"]", "[\"Operational Efficiency\"]", "TODO: Seems redundant with Response Time", "TODO"
Return on Investment, "[\"ROI\"]", "[\"Data Monetization\"]", "Measures the profitability or efficiency of an investment, comparing net gains to costs.", "Measures the profitability or efficiency of an investment, comparing net gains to costs."
Revenue, "[\"Economic Benefits\"]", "[\"Data Monetization\"]", "Refers to the total income from normal business operations. Represents the top line of an income statement.", "Refers to the total income from normal business operations. Represents the top line of an income statement."
Risk Cost, "[\"Regulatory Risk\"]", "[\"Data Governance and Compliance\", \"Data Valuation Techniques\"]", "Risk Cost quantifies the total financial impact of a potential data breach, encompassing fines, legal fees, reputation damage, and operational disruption. It is typically calculated by estimating the cost per compromised record and multiplying by the number of records at risk.", "Measures the financial impact of a potential data breach, including fines, legal fees, reputation damage, and operational disruption. Risk Cost is defined as the total monetary impact incurred by an organization if a data breach, compromise, or loss occurs. It is computed by quantifying various financial and reputational damages and multiplying these by the number of records at risk."
Risk Score, "[\"Risk Management Index\"]", "[\"Data Governance and Compliance\"]", "A metric that quantifies the overall risk level of a data store by systematically evaluating factors like sensitivity and protection through a weighted scoring model.", "Refers to the systematic process of identifying, assessing, and mitigating risks associated with data assets. Risk score is calculated as a weighted sum of multiple risk factors, including sensitivity level and protection percentage, to reflect the overall risk level of a data store."
Information Frequency, "[]", "[\"Data Quality\"]", "TODO", "Measures how often information is updated, accessed, or used. It is more about the rhythm or rate of interaction with the information. TODO: Needs a better explanation to clearly differentiate it from Age and Access Frequency and Granularity."
System Robustness, "[\"System Stability\"]", "[\"Operational Efficiency\"]", "A metric that evaluates how well a system maintains performance and stability under stress, faults, or adversarial conditions, often combining factors like error tolerance, resilience, and generalization.", "Measures the ability of a system, model, or process to remain stable and perform well despite disturbances, faults, or unexpected inputs. Key aspects include system stability, resilience to adversarial attacks, error handling, and generalization. \nDifferent approaches can be done to evaluate System Robustness, as long as they focus on considering a combination of stability, resilence, and the ability to maintain functionality despite errors, faults, generalization to different data and processes, and attacks. An example is included in [79], robustness in the martFL architecture is calculated as the percentage of malicious data providers (DPs) whose low-quality or adversarial local models are successfully excluded during model aggregation."
Data Robustness, "[\"Shapley Robustness\"]", "[\"Operational Efficiency\"]", "Data robustness measures a dataset's reliability and usefulness across prediction tasks by evaluating its resistance to redundancy, manipulation, and replication, often using fairness-focused methods like Shapley-based frameworks.", "Data robustness ensures that datasets maintain their value and usability across various prediction tasks. In [77], robustness is calculated using a Shapley-based framework to ensure fair value allocation in a data marketplace. It identifies and penalizes replicated or redundant datasets using similarity metrics, reducing their contribution weight. Robustness is evaluated by simulating replication scenarios and measuring the system's ability to maintain fair value distribution and resist manipulation, demonstrating effectiveness against adversarial behaviors."
Runtime, "[\"Processing Time\"]", "[\"Operational Efficiency\"]", "TODO", "Refers to the time taken to execute tasks or processes in a data system. Runtime overhead evaluates performance improvements or degradations relative to a baseline. TODO: Seems redundant with response time, needs a better definition to differentiate it."
Satisfaction, "[\"User Feedback\", 'User's Satisfaction', \"User Attitude\", \"User Behaviour\", \"Business User Satisfaction\", \"Degree of Satisfaction\"]", "[\"Customer Needs and Satisfaction\"]", "TODO", "Measures user satisfaction with the platform interface, layout, and data presentation. Combines objective metrics like accuracy and relevance with subjective feedback to gauge satisfaction. TODO: Needs more examples in the explanation."
Scalability, "[\"System Concurrent Processing Capabilities\", \"Elasticity\"]", "[\"Operational Efficiency\"]", "Scalability evaluates a system’s capacity to efficiently handle growing data volumes and workloads, incorporating metrics like throughput, response time, concurrency, velocity, and elasticity, while maintaining performance and cost-effectiveness across dynamic conditions.", "Evaluates the ability of a system to handle increased data volumes. Elasticity allows dynamic allocation of resources to meet demand, ensuring performance and cost-efficiency. Scalability as a metric or KPI can be linked to the main components refered in the Taxonomy Figure (Redundancy, Interoperability, Extensibility, Adaptability) or use, alternatively, changes in metrics under different circumstances, depending on the system type. For example, this can include:\nThroughput: The amount of data processed or tasks completed over time, reflecting the system's ability to handle increasing workloads [45, 105].\nResponse Time: The time a system takes to respond under different load levels, ensuring real-time performance [63].\nVelocity: The system's efficiency in managing large-scale data volumes [105, 63].\nConcurrency: The number of simultaneous processes or tasks the system can handle without degradation [63, 45].\nElasticity: Metrics that represent performance under dynamic considerations such as those that help to evaluate dynamic resource allocation [61, 105]. \nBaseline Comparison: Performance compared to a baseline, such as R2D2 processing TB-scale data within 5 hours, showcasing scalability [112]."
Scarcity, "[]", "[\"Data Monetization\"]", "Measures the availability or rarity of information.  Scarce information may have limited distribution, impacting its monetization potential.", "Measures the availability or rarity of information.  Scarce information may have limited distribution, impacting its monetization potential."
Schema, "[]", "[\"Data Governance and Compliance\"]", "Schema measures the structural quality and adaptability of a dataset’s schema by evaluating attributes like completeness, flexibility, semantic alignment, standardization, interoperability, and error resilience to ensure effective integration and usage across systems.", "Defines the presence or absence of desired attributes, including clarity, comprehensiveness, flexibility, robustness, and precision of domains. Schema as a metric is measured by evaluating several aspects of a schema's structure, consistency, and alignment. Key approaches include: \nCompleteness: Measuring whether all required fields or attributes are present to support specific use cases.\n Flexibility and Adaptability: Assessing the schema's ability to handle semistructured or schemaless data formats, often using techniques like schema evolution tracking or flexibility scoring.\nSemantic Alignment: Using ontology-based or graph-based methods to determine how well schema elements relate to semantic relationships and integrate with other datasets.\nStandardization: Checking adherence to schema standards (e.g., XML schema) to ensure consistency across systems. \nInteroperability: Evaluating the schema's ability to facilitate data integration, such as schema matching and profiling techniques for joinability and alignment. \nError Detection and Correction: Identifying schema-level inconsistencies, missing data, or incorrect mappings during integration workflows [114, 48]. \nFinally, readers are encouraged to review [130] were different metrics specific for tracking Schema are included."
Security Level Index, "[\"Security Access\", \"Security\"]", "[\"Data Governance and Compliance\"]", "Security quantifies the effectiveness of protective measures safeguarding data against unauthorized access and breaches, evaluated through metrics like confidentiality, incident response, threat detection, encryption quality, regulatory compliance, and aggregated indicators such as the Security Level Index (SLI).", "Measures the protective measures implemented to safeguard data from unauthorized access and breaches. Key aspects include confidentiality, integrity, availability, and compliance with regulations. Based on [27], the Security Level Index (SLI) is not explicitly described in detail with a step-by-step formula or exact estimation method. However, the document provides insights into the framework and components influencing the evaluation of security. In [58], Security is measured using efficiency indicators such as incident response time, threat detection rates, and vulnerability repair effectiveness, which assess the system's operational readiness and resilience. On [13] Security in IoT systems is estimated using trust scores, which combine historical performance data (e.g., reliability) with access control mechanisms to evaluate data reliability and security. in [17] Security is integrated into the overall data value (DV) through metrics such as encryption quality, protection against breaches, and compliance with standards. Furthermore, in [35], access security is measured by the system's ability to regulate and secure data access in large-scale environments, addressing challenges of data volume and velocity. Finally, the metrics represented in [120] can be used to generate a general Security Level Index. The metrics Average Comparisons per Rule, Accessibility Surface, Application Transaction Rate, Concurrent Connections, Connections Establishment Rate, Connection Tear Down Rate, Defense Depth, Detection Performance, Data Transmission Exposure, Firewall Complexity, Interface Accessibility Surface, IP Fragmentation Handling, Illegal Traffic Handling, Rule Area, Reachability Count, Rogue Change Days, Vulnerability Exposure and other related to communication like Latency, can be used to measure security."
Security Composite Efficiency Indicator, "[\"TODO: Should it have an acronym?\"]", "[\"Data Governance and Compliance\"]", "Combines multiple efficiency indicators to assess overall system performance in cybersecurity. Metrics include equipping coefficient, technical readiness, and penetration testing resilience.", "Combines multiple efficiency indicators to assess overall system performance in cybersecurity. Metrics include equipping coefficient, technical readiness, and penetration testing resilience."
Shapley Value, "[]", "[\"Data Valuation Techniques\"]", "A baseline metric to measure the importance of each data provider, dataset, or feature in a coalition of data sources.", "A baseline metric to measure the importance of each data provider, dataset, or feature in a coalition of data sources. Reflects the marginal contribution of each data source to the overall system, providing a fair value and reward mechanism."
Social Welfare, "[\"Social Benefits\"]", "[\"Innovation and Growth\", \"Customer Needs and Satisfaction\"]", "TODO", "Represents the difference between the aggregate utility of all model requesters and the total privacy cost of all data owners in a data marketplace. TODO: Needs a better explanation of what that entails."
Statistical Parity, "[]", "[\"Innovation and Growth\"]", "A fairness metric in Machine Learning ensuring equal probability of inclusion in the positive predicted class for sensitive groups. Synthetic data can be adjusted to meet statistical parity requirements.", "A fairness metric in Machine Learning ensuring equal probability of inclusion in the positive predicted class for sensitive groups. Synthetic data can be adjusted to meet statistical parity requirements."
Stochastic Divergence, "[\"Identity-based Exact Match\", \"Shannon Divergence\", \"Wasserstein Distance\"]", "[\"Data Quality\"]", "Stochastic Divergence is a measure of the difference or similarity between statistical distributions, focusing on their probabilistic or statistical characteristics. It encompasses metrics that assess how closely two distributions align or diverge.", "Stochastic Divergence is a measure of the difference or similarity between statistical distributions, focusing on their probabilistic or statistical characteristics. It encompasses metrics that assess how closely two distributions align or diverge."
Structure, "[\"Data Structure\"]", "[\"Data Quality\"]", "Defines the organization and storage format of data, enabling efficient access, modification, and management.", "Defines the organization and storage format of data, enabling efficient access, modification, and management. Structure is assessed in terms of how well data elements are interconnected, standardized, and harmonized within an information system (i.e. it requires Governance Specifications)."
Support, "[]", "[\"Operational Efficiency\"]", "Proportion of records in the dataset that satisfy both the antecedent and consequent of a rule, highlighting common patterns.", "Proportion of records in the dataset that satisfy both the antecedent and consequent of a rule, highlighting common patterns. TODO: Could use a longer explanation with an example."
Syntactic Similarity, "[\"Levenshtein Distance\", \"Edit Distance\", \"Cosine Similarity\", \"Q-gram Distance\", \"Semantic Similarity\"]", "[\"Data Quality\"]", "TODO", "Metrics to assess how similar data values are in terms of their syntax, e.g., based on character similarities. Levenshtein Distance is used as a primary metric to calculate this similarity. Additional metrics include Edit Distance, Cosine Similarity, Q-gram Distance, and Jaccard Coefficient. TODO: Should this be included in Data Similarity? It's just the same applied to text."
System Utilization, "[\"CPU Utilization\", \"Memory Utilization\", \"Disk Utilization\"]", "[\"Operational Efficiency\"]", "Measures how efficiently and effectively a system's resources such as CPU, memory, storage, and network are being used during a given period.", "Measures how efficiently and effectively a system's resources such as CPU, memory, storage, and network are being used during a given period."
System Capacity, "[\"Memory\", \"CPU\", \"Bandwidth\", \"Storage Capacity\"]", "[\"Technology and Infrastructure\"]", "Refers to the maximum amount of work, load, or use that a system can handle without significant degradation in performance. Includes CPU, memory, storage, and bandwidth capacity.", "Refers to the maximum amount of work, load, or use that a system can handle without significant degradation in performance. Includes CPU, memory, storage, and bandwidth capacity. This information can be used also to generate ratios for the System Utilization metric. This is specific to a system configuration and should be readily available."
Network Metrics, "[]", "[\"Operational Efficiency\"]", "TODO", "Metrics specific to data centres operational efficiency that include: Diameter Stretch, Path Stretch, Maximum Relative Size, and Network Utilization. TODO: Could use more explanation of the metrics."
Value of Information for Business, "[\"VIB\"]", "[\"Data Valuation Techniques\"]", "TODO", "Assesses how useful information is for business processes, focusing on accuracy, completeness, relevance, and delay in receiving the information. TODO: Seems redundant with Data Value"
Throughput, "[\"Transaction Processing Speed\"]", "[\"Operational Efficiency\"]", "Measures the number of requests a system can process over a specific period (e.g., requests per second, minute, or hour).", "Measures the number of requests a system can process over a specific period (e.g., requests per second, minute, or hour)."
Timeliness, "[\"Data Freshness\"]", "[\"Data Quality\"]", "TODO", "Measures the availability of data when needed, ensuring data is up-to-date and accessible within an appropriate timeframe. Includes frequency of updates, and speed of availability. The most relevant timeliness metric is data freshness.  It is the delay since the last business action recorded in the database. So it can be used directly. Because data timeliness measures the currency of a copy of data stored in a database, we must distinguish the timestamps of business actions and the time when the data pipeline (ETL process) loaded the data into the data warehouse or data lake.TODO: How is this different from Age? Should probably merge them."
Currency, "[]", "[\"Data Quality\"]", "TODO", "Measures the change in data Value given change in time or processes in the data. TODO: That name is utter bullshit and completely wrong! And it needs a better explanation with an explicit link with timeliness/age."
Traceability, "['Addressability, \"NGD\", \"NDI\", \"NDG\", \"NID\", \"NDGI\", \"Verifiability\"]", "[\"Data Governance and Compliance\"]", "Traceability measures the ability to track, verify, and document the origin, flow, and transformation of data across its lifecycle, ensuring accountability, data integrity, and compliance through data lineage, provenance, audit trails, and governance alignment.", "Refers to the ability to track and verify the lineage of data throughout its lifecycle. Key aspects include: \nData Lineage: this involves mapping the flow of data from its source through various transformations and processes to its final use. It helps in understanding how data changes over time and the impact of those changes. \nProvenance: this refers to the history of the data, including its origin, the processes it has undergone, and any changes made to it. Provenance provides context and helps in assessing the reliability and quality of the data.\nAudit Trails: maintaining records of all changes made to data, including who made the changes, when they were made, and what the changes were. This is essential for accountability and compliance.\nCompliance with governance standards: traceability is often required to meet regulatory standards and governance policies, ensuring that organizations can demonstrate data integrity and accountability. \nAddressability analogously defines the approach to contact or address the origin of the data. TODO: All these acronyms were already defined and need to be merged into this one."
Lineage, "[]", "[\"Data Governance and Compliance\"]", "TODO", "Refers to the entire history of the data, including its origin as well as all the transformations, movements, and processes it has undergone throughout its lifecycle. TODO: Seems a bit redundant with Traceability"
Transparency, "[\"Objective Measurement\"]", "[\"Innovation and Growth\", \"Market Penetration\", \"Data Governance and Compliance\"]", "Transparency measures how easily data and processes can be identified, understood, and interpreted, often assessed through clarity of presentation, consistency in analysis, and governance frameworks, as well as explainability and documentation in data transformations and AI models.", "Refers to the ease of identifying, understanding, and interpreting data and processes. Includes clarity in presenting results and consistency in analysis. In data governance, transparency is measured using structured assessment frameworks like: DAMA-DMBOK Framework (Data Management Body of Knowledge); COBIT 2019 (Control Objectives for Information and Related Technologies); ISO/IEC 15504 (Data Quality Standard)\nFor data transformation and AI models, Transparency is assessed based on explainability, fairness, and model documentation."
Trustworthiness, "[\"Assurance\", \"Trust Score\"]", "[\"Innovation and Growth\"]", "Trustworthiness refers to the believability of data based on integrity, reliability, and consistency, and can be quantified using a Trust Score that combines reputation, credibility, data quality, and transaction history, each weighted by their importance.", "Refers to the believability or trustworthiness of data, often based on its integrity, reliability, and consistency. From [21]: Trust Score (TS) is derived from reputation and credibility without involving a centralized authority. A general equation for Trustworthiness (Trust Score, TS) can be formulated based on the components outlined in the literature. For example: \n\nTS = w1·R + w2·C + w3·Q + w4·T \n\nwhere: R = Reputation Score, derived from verified identity status and historical trust ratings; C = Credibility Score, based on feedback and ratings from past interactions; Q = Data Quality Score, including completeness, accuracy, and consistency; T = Transaction History Score, evaluating the frequency and success rate of transactions; w1, w2, w3, w4 = Weighting factors, predefined based on importance."
Typicality, "[]", "[\"Data Quality\"]", "Measures how well a data point aligns with expected or 'typical' patterns within a dataset. It helps identify outliers or unusual events using statistical or machine learning methods.", "Measures how well a data point aligns with expected or 'typical' patterns within a dataset. It helps identify outliers or unusual events using statistical or machine learning methods."
Uniqueness, "[\"Percentage of Duplicates\", \"Concentration\", \"Redundancy\"]", "[\"Data Quality\"]", "Ensures that each record in a dataset is distinct, avoiding duplicates.", "Ensures that each record in a dataset is distinct, avoiding duplicates. This also can be linked to data systems, in which the reference of Redundancy is linked to the number of repeated datasets that support System Robustness."
Usability, "[\"Usage\", \"Ease of Use\", \"Friendliness\"]", "[\"Data Quality\"]", "TODO", "The ease and efficiency with which quality data (Data-Value, Accuracy, Integrity, Completeness) can be effectively accessed (Communnication, Accessibility, Timeliness), understood (Clarity), and correctly be utilized (Easy-to-use or Utilization & Performance, Relevance or Utility) by users to accomplish specific tasks. TODO: Seems to be an aggregate of a lot of other metrics. Expand the explanation to make it clearer."
Easy-to-Use, "[\"Ease of Use\", \"User Friendliness\"]", "[\"Data Quality\"]", "TODO: Seems to refer to a system more than the data itself. Seems redundant with Clarity, Accessibility, or Discoverability. Needs a better definition to differentiate it if it is different.", "The degree to which a system, product, or interface is designed to enable users to efficiently, effectively, and satisfactorily achieve their goals with minimal effort and complexity, ensuring accessibility and user-friendliness in operation and learning."
Utility, "[\"Application Characteric Index\", \"Retention\"]", "[\"Data Valuation Techniques\"]", "Utility measures how effectively a dataset or system contributes to achieving strategic and operational goals, factoring in organizational use, data processes, quality, and constraints, and can be quantified through a structured utility function or scoring system reflecting its overall functional value.", "Utility, within the context of data valuation, refers to the effectiveness of a resource (e.g., datasets or systems) in achieving objectives. Unlike usability, which includes ease of interaction and other aspects, utility evaluates the functional contribution of the resource to possible outcomes. Furthermore, utility even though similar, is not the same as relevance. Relevance is linked to the specific use case and thus is connected to specific domains, while utility is more general.\nUtility, as specified in this work, could be represented mathematically as a continuous function U (i, j, k, l), where i denotes the organisational activities that could use the data, j represents the data/processes needed to generate information (e.g. if data is distributed and steps required to construct), k corresponds to the quality dimension (e.g., accuracy or timeliness), and l indicates the penalty terms (e.g. like costs and legal binding associated with the data). This formalization allows for the systematic evaluation of utility as a function of the resource's effectiveness in achieving strategic and operational objectives.\nThe general structure of relevance (to calculate the utility function is): \n\nRi,j,k,l = R(Organizational(i), Intrinsic(j), Quality(k); Penalty(l)). \n\nIf a process or activity does not influence a dataset or vice versa, the utility value is defined as U (i, j, k, l) = 0. To evaluate the total utility, you can aggregate the relevance. This aggregation is expressed as a KPI as: \n\nTotal Utility = Σ Σ Σ Σ wi × wj × wk × wl × R(i, j, k, l). \n\nas a metric, utility can be calculated using Kolmogorov statistics. The Kolmogorov statistic can be used to compute utility in scenarios where utility is defined as the retention of the functional value of data after transformations like obfuscation, anonymization, or other data modifications. This approach leverages the Kolmogorov statistic to quantify the similarity between the original and transformed (e.g., obfuscated) data distributions. \nFinally, Utility and Relevance of a dataset can be measured using expert knowledge based on scoring system focusing on the context of the information. In casethe scoring system is used, it could be transformed to be defined as a KPI."
Validity, "[]", "[\"Data Quality\"]", "Validity refers to the extent to which data values conform to predefined rules and logical conditions, ensuring that each entry meets the necessary business or domain-specific criteria for correctness (e.g. the age of a person must be an integer).", "As defined in [TODO: Broken reference], this dimension refers to the compliance of the information the business rules that describe it (e.g. the age of a person must be an integer). Therefore it differs from accuracy. Validity in [9] is defined as the adherence of data values to specified criteria, ensuring that each data entry is logically sound and meets predefined conditions. This is typically done by applying specific rules to the dataset. For example, a rule might state, ”Asset Cost in any Asset record must be greater than zero,” which would flag any entries with a non-positive asset cost as invalid."
Value Added, "[\"Diminishing Value\"]", "[\"Data Valuation Techniques\"]", "TODO", "Value-Added and Diminishing Value metrics reflect the relevance and economic utility of data over time. While Value-Added emphasizes the contribution of data to decision-making or operational efficiency, Diminishing Value highlights the temporal decline in data's utility, particularly critical in sectors like IoT and real-time monitoring systems, where up-to-date information is essential for maintaining competitive advantage [13, 84, 114]. TODO: Seems unclear how Diminishing Value differs from Timeliness and 'Currency' metrics. Value Added seems similar to Utility or Data Value."
Uniformity, "[]", "[\"TODO: Undefined\"]", "TODO", "Uniformity as a metric measures the consistency of data representation across datasets, systems, or within a single dataset. This metric has been conceptualized in this work and could not be relevant at all. TODO: What? Why is it here if it's not relevant? Plus, it seems similar to Accessibility and Clarity, and Consistency."
Synchronization, "[]", "[\"Data Quality\"]", "TODO", "Can be explicitly defined in quantitative terms based on its role in assessing the alignment and coherence of systems or datasets. TODO: That explanation seems off, and/or incomplete. Needs to elaborate on what it is exactly."
Competitive Advantage, "[]", "[\"TODO: Unsure\"]", "Competitive Advantage measures the strategic value of data in providing a unique edge over competitors, typically assessed by evaluating the potential impact if rivals gain access to the same data or if the data is lost.", "Competitive Advantage as a data value dimension refers to the degree to which an organization's data provides a unique strategic edge over competitors. According to the referenced work, competitive advantage is assessed by examining the impact of competitors gaining access to the same data. If competitors possess the data, the potential consequences range from negligible effects to severe impacts on business operations and market position. Metrics include insights into important business processes, the ability to replicate operational advantages, and potential for competitors to gain significant leverage or strategic benefits.\nCompetitive advantage can be measured through the responses to questions such as: What happens if your competitor has access to the same data? Or What happens if you lose this data? Scores can be assigned based on severity: No impact (competitor has irrelevant data), Moderate impact (insight into processes), Significant impact (loss of competitive positioning)."
Value of Privacy, "[\"Privacy Cost\"]", "[\"Data Monetization\"]", "Minimum payment required for sharing data at a specific privacy level (ϵ). Balances privacy loss with data utility.", "Minimum payment required for sharing data at a specific privacy level (ϵ). Balances privacy loss with data utility. TODO: Could do with a longer explanation. Seems very similar Cost of Degradation."
Privacy Level, "[]", "[\"Data Monetization\"]", "TODO", "The privacy level (ϵ) is defined in the context of differential privacy and quantifies the amount of privacy loss incurred when sharing data. It determines how much an individual's private data can influence the reported data."
Variety, "[\"Multifacetedness\"]", "[\"Data Quality\"]", "Variety measures the diversity and complexity of data types, formats, and sources, reflecting the richness of information available for analysis.", "Refers to the diversity of data types and formats. Variety emphasizes the complexity and richness of data attributes for comprehensive analysis. Variety (or Multifacetedness) can be measured by quantifying the diversity in data types, formats, sources, and the number of features in a dataset. Metrics include the count of distinct data types and sources, the number of features or attributes, schema differences, and semantic diversity. Entropy-based measures and sparsity analysis can also assess variability within categorical features or across datasets, offering a comprehensive view of variety [104, 48, 35, 29]."
Views, "[]", "[\"Market Penetration\"]", "TODO: definitely redundant with Downloads and Access Frequency, should probably be merged into one of them.", "TODO"
Visualization, "[]", "[\"TODO: Unsure\"]", "TODO: Could it be merged with Clarity and/or Learnability", "Refers to the graphical representation of data using charts, graphs, maps, and diagrams. Effective visualizations improve clarity, accuracy, and relevance for quick insights and decision-making. There is no specification on the reference material. Nevertheless, metrics for assessing visualization can include the variety of visualization types available (e.g., charts, maps, and graphs), customization options for users to modify visual elements, and the level of interactivity, such as filtering or real-time updates. Additional considerations include the integration of multiple datasets, accessibility standards compliance, and clarity in design to ensure effective communication of data insights. These features can be evaluated both quantitatively, by measuring their availability and functionality, and qualitatively, through user feedback and expert review. An integrated assessment can further combine these factors into broader usability frameworks."
Volatility, "[]", "[\"Data Quality\"]", "TODO: Seems awfully similar to Diminishing Value", "Measures the extent and speed at which data values change over time. Volatility is critical in domains like finance or social media where rapid fluctuations occur."
Volume, "[\"Quantity\", \"Entries\"]", "[\"Data Quality\"]", "Represents the total amount of data available.", "Represents the total amount of data available for analysis, influencing reliability, pattern recognition, and machine learning. Adequate quantity must pair with high quality for actionable insights."
Wasserstein Distance, "[\"Wasserstein Distribution\"]", "[\"Data Quality\"]", "TODO: Not sure how this is relevant here since it's really a generic distance measure, why include this one and not others then?", "Measures the difference between two probability distributions, quantifying how much the empirical distribution deviates from the true distribution."
Weighted Coverage Function, "[]", "[\"Data Valuation Techniques\"]", "TODO", "This function assigns weights to database instances, adjusting prices for queries based on the seller's inputs. It reflects information disclosure. TODO: Definitely needs an expanded explanation."
Winning Rate, "[]", "[\"Market Penetration\"]", "TODO", "Measures the percentage of queries a data provider successfully serves, relative to the queries they are eligible to serve. Higher rates indicate valued offerings. TODO: Needs some more explanation to add context to this."
Proximity, "[]", "[\"Data Quality\"]", "TODO", "Proximity is important in applications like fog computing and habitat monitoring, where the location of events or sensors affects data valuation. TODO: not a definition."
Rival Access Loss, "[]", "[\"Data Valuation Techniques\"]", "TODO: How is that different from Competitive Advantage?", "Estimates the financial cost to a business if competitors gain access to its data."
Field Value, "[]", "[\"Data Monetization\"]", "Field Value represents the importance or worth of a specific data attribute based on its impact on business goals, model performance, market comparisons, cost, uniqueness, and contribution to outcomes.", "Field Value refers to the relative worth or importance of a specific data field (or column) within a dataset. It represents how valuable that single attribute is for the business, model, or system that uses the data. Field value can be determined through multiple approaches:\n\n Market-Based Valuation:\n - Data Price: Derived from the pricing of similar datasets in data marketplaces.\n - Comparison with Similar Data: Benchmarking against prices of comparable datasets. \n\nUtility-Based Valuation:\n - Direct Contribution to Outcomes: Fields significantly impacting operations or models hold higher value.\n - Data Usage Metrics: Frequently accessed or used fields may have higher utility. \n\nCost-Based Valuation:\n - Data Acquisition Cost (DAC): Based on costs for collection, storage, and processing.\n - Maintenance and Update Costs: Ongoing efforts for accuracy and currency. \n\nContent-Based Valuation:\n - Uniqueness and Rarity: Unique or hard-to-collect fields hold higher value.\n - Completeness and Accuracy: High-quality fields improve reliability and are valued more. Risk-Based Valuation:\n - Opportunity Cost: Value based on the cost of not having the field's data.\n - Loss of Information Value (LIV): Impact of the data being unavailable or compromised. \n\nModel-Based Techniques:\n - Shapley Value: Estimates each field's contribution to a predictive model's accuracy. Fields with significant model impact are more valuable."
Growth Rate, "[]", "[\"Data Valuation Techniques\"]", "Growth Rate measures the increase in the number of records within a dataset over time.", "Growth Rate measures the increase in the number of records within a dataset over time. This metric tracks the expansion of data volume and provides insights into data collection and acquisition trends. A higher growth rate indicates enhanced data generation or collection capabilities, while a stable or declining rate may signal data input limitations. It is essential for planning, scalability, storage, and future data resource value."
Storage Cost, "[\"Cost of Data Storage\"]", "[\"Data Valuation Techniques\"]", "The expenses incurred in storing data, encompassing the infrastructure, management, and maintenance of data storage systems.", "The expenses incurred in storing data, encompassing the infrastructure, management, and maintenance of data storage systems. This includes direct costs such as hardware, cloud services, and energy consumption, as well as indirect costs like redundancy, duplication, and compliance with data retention policies. Inefficiencies in managing redundant or unused data can significantly inflate storage costs, as highlighted in discussions of data lakes and enterprise data management strategies [112, 24]. TODO: Isn't that already included in OPEX?"
Ease of Measurement, "[]", "[\"Data Valuation Techniques\"]", "Ease of Measurement indicates how readily a data value dimension can be quantified using available tools, models, or frameworks, reflecting the effort and complexity involved in its assessment.", "Ease of Measurement as a metric refers to the degree to which a particular data value dimension can be quantified or assessed effectively using established methods, tools, or frameworks. It serves as an indicator of how practical or straightforward it is to evaluate a data value dimension, considering the availability of standardized metrics, models, or processes. In other words, it measures the effort and complexity involved in determining a data value dimension. This can be used as a supporting metric within data valuation techniques to prioritize dimensions that are easier to measure while identifying areas that may require additional effort or contextual understanding."